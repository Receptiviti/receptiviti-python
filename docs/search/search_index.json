{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A Python package to process text with the Receptiviti API.</p> <p>An R package is also available at Receptiviti/receptiviti-r.</p>"},{"location":"#installation","title":"Installation","text":"<p>If needed, download Python from python.org, then install the package with pip:</p> <p>Release (version 0.1.2)</p> <pre><code>pip install receptiviti\n</code></pre> <p>Development</p> <pre><code>pip install git+https://github.com/receptiviti/receptiviti-python.git\n</code></pre> <p>And load the package in a Python console:</p> <pre><code>import receptiviti\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<pre><code># score a single text\nsingle = receptiviti.request(\"a text to score\")\n\n# score multiple texts, and write results to a file\nmulti = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n\n# score texts in separate files\n## defaults to look for .txt files\nfile_results = receptiviti.request(directory = \"./path/to/txt_folder\")\n\n## could be .csv\nfile_results = receptiviti.request(\n  directory = \"./path/to/csv_folder\",\n  text_column = \"text\", file_type = \"csv\"\n)\n\n# score texts in a single file\nresults = receptiviti.request(\"./path/to/file.csv\", text_column = \"text\")\n</code></pre>"},{"location":"#api-access","title":"API Access","text":"<p>To access the API, you will need to load your key and secret, as found on your dashboard.</p> <p>You can enter these as arguments in each function call, but by default they will be looked for in these environment variables:</p> <pre><code>RECEPTIVITI_KEY=\"32lettersandnumbers\"\nRECEPTIVITI_SECRET=\"56LettersAndNumbers\"\n</code></pre> <p>You can store these in a <code>.env</code> file (in the current directory or <code>~/Documents</code>) permanently, or set them temporarily:</p> <pre><code>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</code></pre>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#receptiviti-013","title":"receptiviti 0.1.3","text":""},{"location":"CHANGELOG/#additions","title":"Additions","text":"<ul> <li>Adds <code>collect_results</code> option for cache-only output.</li> <li>Adds framework checking and listing functionality.</li> <li>Adds custom norming context creation functionality.</li> <li>Adds support for V2 of the API.</li> </ul>"},{"location":"CHANGELOG/#improvements","title":"Improvements","text":"<ul> <li>Makes <code>pyarrow</code> optional.</li> <li>Improves cache performance.</li> <li>Validates <code>version</code> and <code>endpoint</code>.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Avoids overwriting existing cache results within overlapping bins on update.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-012","title":"receptiviti 0.1.2","text":""},{"location":"CHANGELOG/#improvements_1","title":"Improvements","text":"<ul> <li>Changes default number of cores to 1, to avoid unexpected behavior when running from a script.</li> <li>Improves environment file resolution.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>Corrects order of output when reading from a file and <code>ids</code> are not specified.</li> <li>Fixes detection of some file encodings.</li> <li>Avoids issues when <code>receptiviti.request</code> is called from a script and is processing in parallel.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-011","title":"receptiviti 0.1.1","text":""},{"location":"CHANGELOG/#improvements_2","title":"Improvements","text":"<ul> <li>Adds <code>encoding</code> argument; improves handling of non-UTF-8 files.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>Fixes reading in files when <code>collapse_line</code> is <code>True</code>.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-010","title":"receptiviti 0.1.0","text":"<p>First release.</p>"},{"location":"articles/high_volume/","title":"High Volume","text":"<p>The Receptiviti API has limits on bundle requests, so the <code>receptiviti.request()</code> function splits texts into acceptable bundles, to be spread across multiple requests.</p> <p>This means the only remaining limitation on the number of texts that can be processed comes from the memory of the system sending requests.</p> <p>The basic way to work around this limitation is to fully process smaller chunks of text.</p> <p>There are a few ways to avoid loading all texts and results.</p> In\u00a0[2]: Copied! <pre>from os import makedirs\n\nbase_dir = \"../../../\"\ntext_dir = base_dir + \"test_texts\"\nmakedirs(text_dir, exist_ok=True)\n\nfor i in range(10):\n    with open(f\"{text_dir}/example_{i}.txt\", \"w\", encoding=\"utf-8\") as file:\n        file.write(f\"An example text {i}.\")\n</pre> from os import makedirs  base_dir = \"../../../\" text_dir = base_dir + \"test_texts\" makedirs(text_dir, exist_ok=True)  for i in range(10):     with open(f\"{text_dir}/example_{i}.txt\", \"w\", encoding=\"utf-8\") as file:         file.write(f\"An example text {i}.\") <p>And then minimally load these and their results by saving results to a Parquet dataset.</p> <p>Disabling the <code>request_cache</code> will also avoid storing a copy of raw results.</p> In\u00a0[3]: Copied! <pre>import receptiviti\n\ndb_dir = base_dir + \"test_results\"\nmakedirs(db_dir, exist_ok=True)\n\nreceptiviti.request(\n  text_dir, collect_results=False, cache=db_dir, request_cache=False\n)\n</pre> import receptiviti  db_dir = base_dir + \"test_results\" makedirs(db_dir, exist_ok=True)  receptiviti.request(   text_dir, collect_results=False, cache=db_dir, request_cache=False ) <p>Results are now available in the cache directory, which you can load in using the request function again:</p> In\u00a0[4]: Copied! <pre># adding make_request=False just ensures requests are not made if not found\nresults = receptiviti.request(text_dir, cache=db_dir, make_request=False)\nresults.iloc[:, 0:3]\n</pre> # adding make_request=False just ensures requests are not made if not found results = receptiviti.request(text_dir, cache=db_dir, make_request=False) results.iloc[:, 0:3] Out[4]: id text_hash summary.word_count 0 ../../../test_texts\\example_0.txt b88ba15b5436224a66b02f13b11b13db 4 1 ../../../test_texts\\example_1.txt 4ab51432a48a54d4fd780d226d0c3f1c 4 2 ../../../test_texts\\example_2.txt 786744d45ec2d0e302394dc2ececa004 4 3 ../../../test_texts\\example_3.txt bb2ced7fa2cf67ec2aa974bac3cfb609 4 4 ../../../test_texts\\example_4.txt 507616854eb89e3d12e49001fe4333c8 4 5 ../../../test_texts\\example_5.txt b80b47a8f2def76f4c256108053dda50 4 6 ../../../test_texts\\example_6.txt 3c3d708014a7c25ee468afbd32843dab 4 7 ../../../test_texts\\example_7.txt fbc965c3d7b8cb1f487789bb9a313efa 4 8 ../../../test_texts\\example_8.txt 11fa50aa3392a971cb0dc098d8efc5a4 4 9 ../../../test_texts\\example_9.txt 72c5453f604e9493e3d7619542272068 4 In\u00a0[5]: Copied! <pre>res_dir = base_dir + \"text_results_manual\"\nmakedirs(res_dir, exist_ok=True)\n\n# using the same files as before\nfiles = os.listdir(text_dir)\n\n# process 5 files at a time\nfor i in range(0, len(files), 5):\n  file_subset = files[i : i + 5]\n  results = receptiviti.request(\n    file_subset, ids=file_subset, cores=1, cache=False, request_cache=False\n  )\n  results.to_csv(f\"{res_dir}/files_{i}-{i + 5}.csv.xz\", index=False)\n</pre> res_dir = base_dir + \"text_results_manual\" makedirs(res_dir, exist_ok=True)  # using the same files as before files = os.listdir(text_dir)  # process 5 files at a time for i in range(0, len(files), 5):   file_subset = files[i : i + 5]   results = receptiviti.request(     file_subset, ids=file_subset, cores=1, cache=False, request_cache=False   )   results.to_csv(f\"{res_dir}/files_{i}-{i + 5}.csv.xz\", index=False) <p>Now results will be stored in smaller files:</p> In\u00a0[6]: Copied! <pre>from pandas import read_csv\n\nread_csv(f\"{res_dir}/files_0-5.csv.xz\").iloc[:, 0:3]\n</pre> from pandas import read_csv  read_csv(f\"{res_dir}/files_0-5.csv.xz\").iloc[:, 0:3] Out[6]: id text_hash summary.word_count 0 example_0.txt d64abeb882f39496db62fc1efe68e535 3 1 example_1.txt 29b8f4db53466ab0f1a8c00320163a49 3 2 example_2.txt 2e558b39f1788d89dd8ff4c54f3e8d98 3 3 example_3.txt 41f5570eae91ab3f9792fe11febbc591 3 4 example_4.txt 039d1cd61e9daecb0e39de17d898eb6d 3"},{"location":"articles/high_volume/#high-volume","title":"High Volume\u00b6","text":""},{"location":"articles/high_volume/#cache-as-output","title":"Cache as Output\u00b6","text":"<p>Setting the <code>collect_results</code> argument to <code>False</code> avoids retaining all batch results in memory as they are receive, but means results are not returned, so the they have to be collected in the cache.</p> <p>If texts are also too big to load into memory, they can be loaded from files at request time. By default, when multiple files pointed to as <code>text</code>, the actual texts are only loaded when they are being sent for scoring, which means only <code>bundle_size</code> * <code>cores</code> texts are loaded at a time.</p> <p>We can start by writing some small text examples to files:</p>"},{"location":"articles/high_volume/#manual-chunking","title":"Manual Chunking\u00b6","text":"<p>A more flexible approach would be to process smaller chunks of text normally, and handle loading and storing results yourself.</p> <p>In this case, it may be best to disable parallelization, and explicitly disable the primary cache (in case it's specified in an environment variable).</p>"},{"location":"articles/quick_start/","title":"Get Started","text":"In\u00a0[2]: Copied! <pre>import receptiviti\n</pre> import receptiviti In\u00a0[3]: Copied! <pre>receptiviti.status()\n</pre> receptiviti.status() <pre>Status: OK\nMessage: 200: Hello there, World!\n</pre> Out[3]: <pre>&lt;Response [200]&gt;</pre> <p>If your credentials are not recognized, you'll get a response like this:</p> In\u00a0[4]: Copied! <pre>receptiviti.status(key=123, secret=123)\n</pre> receptiviti.status(key=123, secret=123) <pre>Status: ERROR\nMessage: 401 (1411): Unrecognized API key pair. This call will not count towards your plan.\n</pre> Out[4]: <pre>&lt;Response [401]&gt;</pre> In\u00a0[5]: Copied! <pre>results = receptiviti.request(\"texts to score\")\n</pre> results = receptiviti.request(\"texts to score\") <p>Or a character vector:</p> In\u00a0[6]: Copied! <pre>results = receptiviti.request([\"text one\", \"text two\"])\n</pre> results = receptiviti.request([\"text one\", \"text two\"]) <p>Or from a <code>DataFrame</code>:</p> In\u00a0[7]: Copied! <pre>import pandas\ndata = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})\n\n# directly\nresults = receptiviti.request(data[\"text\"])\n\n# by column name\nresults = receptiviti.request(data, text_column=\"text\")\n</pre> import pandas data = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})  # directly results = receptiviti.request(data[\"text\"])  # by column name results = receptiviti.request(data, text_column=\"text\") In\u00a0[8]: Copied! <pre># single\nresults = receptiviti.request(\"files/file.txt\")\n\n# multiple\nresults = receptiviti.request(\n  files = [\"files/file1.txt\", \"files/file2.txt\"]\n)\n</pre> # single results = receptiviti.request(\"files/file.txt\")  # multiple results = receptiviti.request(   files = [\"files/file1.txt\", \"files/file2.txt\"] ) <p>Or to a comma delimited file with a column containing text. Here, the <code>text_column</code> argument specifies which column contains text:</p> In\u00a0[9]: Copied! <pre># single\nresults = receptiviti.request(\"files/file.csv\", text_column=\"text\")\n\n# multiple\nresults = receptiviti.request(\n  files = [\"files/file1.csv\", \"files/file2.csv\"],\n  text_column=\"text\"\n)\n</pre> # single results = receptiviti.request(\"files/file.csv\", text_column=\"text\")  # multiple results = receptiviti.request(   files = [\"files/file1.csv\", \"files/file2.csv\"],   text_column=\"text\" ) <p>Or you can point to a directory containing text files:</p> In\u00a0[10]: Copied! <pre>results = receptiviti.request(directory = \"files\")\n</pre> results = receptiviti.request(directory = \"files\") <p>By default <code>.txt</code> files will be looked for, but you can specify <code>.csv</code> files with the <code>file_type</code> argument:</p> In\u00a0[11]: Copied! <pre>results = receptiviti.request(\n  directory = \"files\",\n  text_column=\"text\", file_type=\"csv\"\n)\n</pre> results = receptiviti.request(   directory = \"files\",   text_column=\"text\", file_type=\"csv\" ) In\u00a0[12]: Copied! <pre>results = receptiviti.request(\"texts to score\")\nresults.iloc[:, :3]\n</pre> results = receptiviti.request(\"texts to score\") results.iloc[:, :3] Out[12]: text_hash summary.word_count summary.words_per_sentence 0 acab8277267d0efee0828f94e0919ddf 3 3 <p>Here, the first column (<code>text_hash</code>) is the MD5 hash of the text, which identifies unique texts, and is stored in the main cache.</p> <p>The entered text can also be included with the <code>return_text</code> argument:</p> In\u00a0[13]: Copied! <pre>results = receptiviti.request(\"texts to score\", return_text=True)\nresults[[\"text_hash\", \"text\"]]\n</pre> results = receptiviti.request(\"texts to score\", return_text=True) results[[\"text_hash\", \"text\"]] Out[13]: text_hash text 0 acab8277267d0efee0828f94e0919ddf texts to score <p>You can also select frameworks before they are all returned:</p> In\u00a0[14]: Copied! <pre>results = receptiviti.request(\"texts to score\", frameworks=\"liwc\")\nresults.iloc[:, :5]\n</pre> results = receptiviti.request(\"texts to score\", frameworks=\"liwc\") results.iloc[:, :5] Out[14]: text_hash analytical_thinking clout authentic emotional_tone 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 0.257742 <p>By default, a single framework will have column names without the framework name, but you can retain these with <code>framework_prefix=True</code>:</p> In\u00a0[15]: Copied! <pre>results = receptiviti.request(\n  \"texts to score\",\n  frameworks=\"liwc\", framework_prefix=True\n)\nresults.iloc[:, :4]\n</pre> results = receptiviti.request(   \"texts to score\",   frameworks=\"liwc\", framework_prefix=True ) results.iloc[:, :4] Out[15]: text_hash liwc.analytical_thinking liwc.clout liwc.authentic 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 In\u00a0[16]: Copied! <pre>data = pandas.DataFrame({\n  \"id\": [1, 2, 3, 4],\n  \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"]\n})\nresults = receptiviti.request(data[\"text\"])\n\n# combine data and results\ndata.join(results).iloc[:, :5]\n</pre> data = pandas.DataFrame({   \"id\": [1, 2, 3, 4],   \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"] }) results = receptiviti.request(data[\"text\"])  # combine data and results data.join(results).iloc[:, :5] Out[16]: id text text_hash summary.word_count summary.words_per_sentence 0 1 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 1 2 NaN NaN NaN NaN 2 3 NaN NaN NaN 3 4 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 <p>You can also provide a vector of unique IDs to be returned with results so they can be merged with other data:</p> In\u00a0[17]: Copied! <pre>results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"])\nresults.iloc[:, :4]\n</pre> results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"]) results.iloc[:, :4] Out[17]: id text_hash summary.word_count summary.words_per_sentence 0 a 42ff59040f004970040f90a19aa6b3fa 2 2 1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 In\u00a0[18]: Copied! <pre># merge with a new dataset\ndata = pandas.DataFrame({\n  \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],\n  \"type\": [\"a\", \"b\", \"a\", \"b\"]\n})\ndata.join(results.set_index(\"id\"), \"type\").iloc[:, :5]\n</pre> # merge with a new dataset data = pandas.DataFrame({   \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],   \"type\": [\"a\", \"b\", \"a\", \"b\"] }) data.join(results.set_index(\"id\"), \"type\").iloc[:, :5] Out[18]: id type text_hash summary.word_count summary.words_per_sentence 0 a1 a 42ff59040f004970040f90a19aa6b3fa 2 2 1 b1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 2 a2 a 42ff59040f004970040f90a19aa6b3fa 2 2 3 b2 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 In\u00a0[19]: Copied! <pre>receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True)\nresults = pandas.read_csv(\"~/Documents/results.csv\")\nresults.iloc[:, :4]\n</pre> receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True) results = pandas.read_csv(\"~/Documents/results.csv\") results.iloc[:, :4] Out[19]: id text_hash summary.word_count summary.words_per_sentence 0 1 acab8277267d0efee0828f94e0919ddf 3 3"},{"location":"articles/quick_start/#install-and-load","title":"Install and Load\u00b6","text":"<p>First, download and install Python from python.org.</p> <p>Then, install the package:</p> <pre>pip install git+https://github.com/receptiviti/receptiviti-python.git\n</pre> <p>Each time you start a Python session, load the package:</p>"},{"location":"articles/quick_start/#set-up-api-credentials","title":"Set Up API Credentials\u00b6","text":"<p>You can find your API key and secret on your dashboard.</p> <p>You can set these credentials up in Python permanently or temporarily:</p>"},{"location":"articles/quick_start/#permanent","title":"Permanent\u00b6","text":"<p>Open or create a <code>~/.env</code> file, Then add these environment variables with your key and secret:</p> <pre>RECEPTIVITI_KEY=\"\"\nRECEPTIVITI_SECRET=\"\"\n</pre> <p>These can be read in with the <code>receptiviti.readin_env()</code> function, which is automatically called if credentials are not otherwise provided (and the <code>dotenv</code> argument is <code>True</code>).</p>"},{"location":"articles/quick_start/#temporary","title":"Temporary\u00b6","text":"<p>Add your key and secret, and run at the start of each session:</p> <pre>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</pre>"},{"location":"articles/quick_start/#confirm-credentials","title":"Confirm Credentials\u00b6","text":"<p>Check that the API is reachable, and your credentials are recognized:</p>"},{"location":"articles/quick_start/#enter-your-text","title":"Enter Your Text\u00b6","text":""},{"location":"articles/quick_start/#loaded-text","title":"Loaded Text\u00b6","text":"<p>If your texts are already in Python, you can enter them directly.</p> <p>These can be in a single character:</p>"},{"location":"articles/quick_start/#text-in-files","title":"Text in files\u00b6","text":"<p>You can enter paths to files containing separate texts in each line:</p>"},{"location":"articles/quick_start/#use-results","title":"Use Results\u00b6","text":""},{"location":"articles/quick_start/#returned-results","title":"Returned Results\u00b6","text":"<p>Results are returned as a <code>DataFrame</code>, with a row for each text, and columns for each framework variable:</p>"},{"location":"articles/quick_start/#aligning-results","title":"Aligning Results\u00b6","text":"<p>Results are returned in a way that aligns with the text you enter originally, including any duplicates or invalid entries.</p> <p>This means you can add the results object to original data:</p>"},{"location":"articles/quick_start/#saved-results","title":"Saved Results\u00b6","text":"<p>Results can also be saved to a <code>.csv</code> file:</p>"},{"location":"articles/quick_start/#preserving-results","title":"Preserving Results\u00b6","text":"<p>The <code>receptiviti.request</code> function tries to avoid sending texts to the API as much as possible:</p> <ul> <li>As part of the preparation process, it excludes duplicates and invalid texts.</li> <li>If enabled, it checks the primary cache to see if any texts have already been scored.<ul> <li>The primary cache is an Arrow database located by the <code>cache</code> augment.</li> <li>Its format is determined by <code>cache_format</code>.</li> <li>You can skip checking it initially while still writing results to it with <code>cache_overwrite=True</code>.</li> <li>It can be cleared with <code>clear_cache=True</code>.</li> </ul> </li> <li>It will check for any responses to previous, identical requests.<ul> <li>Responses are stored in the <code>receptiviti_request_cache</code> directory of your system's temporary directory (<code>tempfile.gettempdir()</code>).</li> <li>You can avoid using this cache with <code>request_cache=False</code>.</li> <li>This cache is cleared after a day.</li> </ul> </li> </ul> <p>If you want to make sure no texts are sent to the API, you can use <code>make_request=False</code>. This will use the primary and request cache, but will fail if any texts are not found there.</p> <p>If a call fails before results can be written to the cache or returned, all received responses will still be in the request cache, but those will be deleted after a day.</p>"},{"location":"articles/quick_start/#handling-big-data","title":"Handling Big Data\u00b6","text":"<p>The <code>receptiviti.request</code> function will handle splitting texts into bundles, so the limit on how many texts you can process at once will come down to your system's amount of random access memory (RAM). Several thousands of texts should be fine, but getting into millions of texts, you may not be able to have all of the results loaded at once. To get around this, you can fully process subsets of your texts.</p> <p>A benefit of processing more texts at once is that requests can be parallelized, but this is more RAM intensive, and the primary cache is updated less frequently (as it is updated only at the end of a complete run).</p> <p>You could also parallelize your own batches, but be sure to set <code>cores</code> to <code>1</code> (to disable the function's parallelization) and do not enable the primary cache (to avoid attempting to read from the cache while it is being written to by another instance).</p> <p>Not using the primary cache is also more efficient, but you may want to ensure you are not sending duplicate texts between calls. The function handles duplicate texts within calls (only ever sending unique texts), but depends on the cache to avoid sending duplicates between calls.</p>"},{"location":"functions/frameworks/","title":"Frameworks","text":"<p>Check the status of the API.</p>"},{"location":"functions/frameworks/#receptiviti.frameworks.frameworks","title":"<code>frameworks(url=os.getenv('RECEPTIVITI_URL', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), dotenv=False)</code>","text":"<p>List Available Frameworks.</p> <p>Retrieve a list of all frameworks available to your account.</p> PARAMETER DESCRIPTION <code>url</code> <p>The URL of the API.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_URL', '')</code> </p> <code>key</code> <p>Your API key.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_KEY', '')</code> </p> <code>secret</code> <p>Your API secret.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_SECRET', '')</code> </p> <code>dotenv</code> <p>Path to a .env file to read environment variables from, or <code>True</code> to look for a file in the current directory.</p> <p> TYPE: <code>bool | str</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of framework names.</p> <p>Examples:</p> <pre><code>receptiviti.frameworks()\n</code></pre> Source code in <code>src\\receptiviti\\frameworks.py</code> <pre><code>def frameworks(\n    url: str = os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    key: str = os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret: str = os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    dotenv: Union[bool, str] = False,\n) -&gt; List[str]:\n    \"\"\"\n    List Available Frameworks.\n\n    Retrieve a list of all frameworks available to your account.\n\n    Args:\n      url (str): The URL of the API.\n      key (str): Your API key.\n      secret (str): Your API secret.\n      dotenv (bool | str): Path to a .env file to read environment variables from, or `True`\n        to look for a file in the current directory.\n\n    Returns:\n      List of framework names.\n\n    Examples:\n        ```python\n        receptiviti.frameworks()\n        ```\n    \"\"\"\n    _, url, key, secret = _resolve_request_def(url, key, secret, dotenv)\n    res = requests.get(url.lower() + \"/v2/frameworks\", auth=(key, secret), timeout=9999)\n    content = res.json() if res.text[:1] == \"[\" else {\"message\": res.text}\n    if res.status_code != 200:\n        msg = f\"Request Error ({res.status_code!s})\" + (\n            (\" (\" + str(content[\"code\"]) + \")\" if \"code\" in content else \"\") + \": \" + content[\"message\"]\n        )\n        raise RuntimeError(msg)\n    return content if isinstance(content, list) else []\n</code></pre>"},{"location":"functions/norming/","title":"Norming","text":"<p>Interact with the norming endpoint.</p>"},{"location":"functions/norming/#receptiviti.norming.norming","title":"<code>norming(name=None, text=None, options=None, delete=False, name_only=False, dotenv=True, key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), url=os.getenv('RECEPTIVITI_URL', ''), verbose=True, **kwargs)</code>","text":"<p>View or Establish Custom Norming Contexts.</p> <p>Custom norming contexts can be used to process later texts by specifying the <code>custom_context</code> API argument in the <code>receptiviti.request</code> function (e.g., <code>receptiviti.request(\"text to score\", version = \"v2\", options = {\"custom_context\": \"norm_name\"})</code>, where <code>norm_name</code> is the name you set here).</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of a new norming context, to be established from the provided 'text'. Not providing a name will list the previously created contexts.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>text</code> <p>Text to be processed and used as the custom norming context. Not providing text will return the status of the named norming context.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to set for the norming context (e.g., <code>{\"word_count_filter\": 350, \"punctuation_filter\": .25}</code>).</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>delete</code> <p>If <code>True</code>, will request removal of the <code>name</code> context.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>name_only</code> <p>If <code>True</code>, will return a list of context names only, including those of build-in contexts.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dotenv</code> <p>Path to a .env file to read environment variables from. By default, will for a file in the current directory or <code>~/Documents</code>. Passed to <code>readin_env</code> as <code>path</code>.</p> <p> TYPE: <code>bool | str</code> DEFAULT: <code>True</code> </p> <code>key</code> <p>Your API key.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_KEY', '')</code> </p> <code>secret</code> <p>Your API secret.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_SECRET', '')</code> </p> <code>url</code> <p>The URL of the API; defaults to <code>https://api.receptiviti.com</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_URL', '')</code> </p> <code>verbose</code> <p>If <code>False</code>, will not show status messages.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>**kwargs</code> <p>Additional arguments to specify how tests are read in and processed; see receptiviti.request.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Union[None, List[str], DataFrame, Series, Dict[str, Union[Series, DataFrame, None]]]</code> <p>Nothing if <code>delete</code> is <code>True</code>. If <code>list_all</code> is <code>True</code>, a <code>list</code> containing context names (built-in and custom). Otherwise, either a <code>pandas.DataFrame</code> containing all existing custom context statuses (if no <code>name</code> is specified), a <code>pandas.Series</code> containing the the status of <code>name</code> (if <code>text</code> is not specified), a dictionary:</p> <ul> <li><code>initial_status</code>: Initial status of the context.</li> <li><code>first_pass</code>: Response after texts are sent the first time, or   <code>None</code> if the initial status is <code>pass_two</code>.</li> <li><code>second_pass</code>: Response after texts are sent the second time.</li> </ul> <p>Examples:</p> <pre><code># list all available contexts:\nreceptiviti.norming()\n\n# list current custom contexts:\nreceptiviti.norming()\n\n# create or get the status of a single context:\nreceptiviti.norming(\"new_context\")\n</code></pre> <p>Send tests to establish the context, just like the receptiviti.request function. <pre><code>## such as directly:\nreceptiviti.norming(\"new_context\", [\"text to send\", \"another text\"])\n\n## or from a file:\nreceptiviti.norming(\"new_context\", \"./path/to/file.csv\", text_column = \"text\")\n\n## delete the new context:\nreceptiviti.norming(\"new_context\", delete=True)\n</code></pre></p> Source code in <code>src\\receptiviti\\norming.py</code> <pre><code>def norming(\n    name: Union[str, None] = None,\n    text: Union[str, List[str], pandas.DataFrame, None] = None,\n    options: Union[dict, None] = None,\n    delete=False,\n    name_only=False,\n    dotenv: Union[bool, str] = True,\n    key=os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret=os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    url=os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    verbose=True,\n    **kwargs,\n) -&gt; Union[None, List[str], pandas.DataFrame, pandas.Series, Dict[str, Union[pandas.Series, pandas.DataFrame, None]]]:\n    \"\"\"\n    View or Establish Custom Norming Contexts.\n\n    Custom norming contexts can be used to process later texts by specifying the\n    `custom_context` API argument in the `receptiviti.request` function (e.g.,\n    `receptiviti.request(\"text to score\", version = \"v2\", options = {\"custom_context\": \"norm_name\"})`,\n    where `norm_name` is the name you set here).\n\n    Args:\n        name (str): Name of a new norming context, to be established from the provided 'text'.\n            Not providing a name will list the previously created contexts.\n        text (str): Text to be processed and used as the custom norming context.\n            Not providing text will return the status of the named norming context.\n        options (dict): Options to set for the norming context (e.g.,\n            `{\"word_count_filter\": 350, \"punctuation_filter\": .25}`).\n        delete (bool): If `True`, will request removal of the `name` context.\n        name_only (bool): If `True`, will return a list of context names only, including those of\n            build-in contexts.\n        dotenv (bool | str): Path to a .env file to read environment variables from. By default,\n            will for a file in the current directory or `~/Documents`.\n            Passed to `readin_env` as `path`.\n        key (str): Your API key.\n        secret (str): Your API secret.\n        url (str): The URL of the API; defaults to `https://api.receptiviti.com`.\n        verbose (bool): If `False`, will not show status messages.\n        **kwargs (Any): Additional arguments to specify how tests are read in and processed;\n            see [receptiviti.request][receptiviti.request].\n\n    Returns:\n        Nothing if `delete` is `True`.\n            If `list_all` is `True`, a `list` containing context names (built-in and custom).\n            Otherwise, either a `pandas.DataFrame` containing all existing custom context statuses\n            (if no `name` is specified), a `pandas.Series` containing the the status of\n            `name` (if `text` is not specified), a dictionary:\n\n            - `initial_status`: Initial status of the context.\n            - `first_pass`: Response after texts are sent the first time, or\n              `None` if the initial status is `pass_two`.\n            - `second_pass`: Response after texts are sent the second time.\n\n    Examples:\n        ```python\n        # list all available contexts:\n        receptiviti.norming()\n\n        # list current custom contexts:\n        receptiviti.norming()\n\n        # create or get the status of a single context:\n        receptiviti.norming(\"new_context\")\n        ```\n\n        Send tests to establish the context, just like\n        the [receptiviti.request][receptiviti.request] function.\n        ```python\n        ## such as directly:\n        receptiviti.norming(\"new_context\", [\"text to send\", \"another text\"])\n\n        ## or from a file:\n        receptiviti.norming(\"new_context\", \"./path/to/file.csv\", text_column = \"text\")\n\n        ## delete the new context:\n        receptiviti.norming(\"new_context\", delete=True)\n        ```\n    \"\"\"\n    _, url, key, secret = _resolve_request_def(url, key, secret, dotenv)\n    auth = requests.auth.HTTPBasicAuth(key, secret)\n    if name_only:\n        if verbose:\n            print(\"requesting list of existing custom norming contests\")\n        req = requests.get(url + \"/v2/norming/\", auth=auth, timeout=9999)\n        if req.status_code != 200:\n            msg = f\"failed to make norming list request: {req.status_code} {req.reason}\"\n            raise RuntimeError(msg)\n        norms = req.json()\n        if norms and verbose:\n            custom_prefix = re.compile(\"^custom/\")\n            print(\"available norming context(s): \" + \", \".join([custom_prefix.sub(\"\", name) for name in norms]))\n        return norms\n\n    url += \"/v2/norming/custom/\"\n    if name and re.search(\"[^a-z0-9_.-]\", name):\n        msg = \"`name` can only include lowercase letters, numbers, hyphens, underscores, or periods\"\n        raise RuntimeError(msg)\n\n    # list current context\n    if verbose:\n        print(\"requesting list of existing custom norming contests\")\n    req = requests.get(url, auth=auth, timeout=9999)\n    if req.status_code != 200:\n        msg = f\"failed to make custom norming list request: {req.status_code} {req.reason}\"\n        raise RuntimeError(msg)\n    norms = pandas.json_normalize(req.json())\n    if not name:\n        if len(norms):\n            if verbose:\n                custom_prefix = re.compile(\"^custom/\")\n                print(\n                    \"custom norming context(s) found: \"\n                    + \", \".join([custom_prefix.sub(\"\", name) for name in norms[\"name\"]])\n                )\n        elif verbose:\n            print(\"no custom norming contexts found\")\n        return norms\n    context_id = \"custom/\" + name\n    if len(norms) and context_id in norms[\"name\"].values:\n        if delete:\n            res = requests.delete(url + name, auth=auth, timeout=9999)\n            content = res.json() if res.text[:1] == \"[\" else {\"message\": res.text}\n            if res.status_code != 200:\n                msg = f\"Request Error ({res.status_code!s})\" + (\n                    (\" (\" + str(content[\"code\"]) + \")\" if \"code\" in content else \"\") + \": \" + content[\"message\"]\n                )\n                raise RuntimeError(msg)\n            return None\n        status = norms[norms[\"name\"] == context_id].iloc[0]\n        if options:\n            warnings.warn(UserWarning(f\"context {name} already exists, so options do not apply\"), stacklevel=2)\n    elif delete:\n        print(f\"context {name} does not exist\")\n        return None\n    else:\n        if verbose:\n            print(f\"requesting creation of context {name}\")\n        req = requests.post(url, json.dumps({\"name\": name, **(options if options else {})}), auth=auth, timeout=9999)\n        if req.status_code != 200:\n            msg = f\"failed to make norming creation request: {req.json().get('error', 'reason unknown')}\"\n            raise RuntimeError(msg)\n        status = pandas.json_normalize(req.json()).iloc[0]\n        if options:\n            for param, value in options.items():\n                if param not in status:\n                    warnings.warn(UserWarning(f\"option {param} was not set\"), stacklevel=2)\n                elif value != status[param]:\n                    warnings.warn(UserWarning(f\"set option {param} does not match the requested value\"), stacklevel=2)\n    if verbose:\n        print(f\"status of {name}:\")\n        print(status)\n    if not text:\n        return status\n    status_step = status[\"status\"]\n    if status_step == \"completed\":\n        warnings.warn(UserWarning(\"status is `completes`, so cannot send text\"), stacklevel=2)\n        return {\"initial_status\": status, \"first_pass\": None, \"second_pass\": None}\n    if status_step == \"pass_two\":\n        first_pass = None\n    else:\n        if verbose:\n            print(f\"sending first-pass sample for {name}\")\n        _, first_pass, _ = _manage_request(\n            text=text,\n            **kwargs,\n            dotenv=dotenv,\n            key=key,\n            secret=secret,\n            url=f\"{url}{name}/one\",\n            to_norming=True,\n        )\n    second_pass = None\n    if first_pass is not None and (first_pass[\"analyzed\"] == 0).all():\n        warnings.warn(\n            UserWarning(\"no texts were successfully analyzed in the first pass, so second pass was skipped\"),\n            stacklevel=2,\n        )\n    else:\n        if verbose:\n            print(f\"sending second-pass samples for {name}\")\n        _, second_pass, _ = _manage_request(\n            text=text,\n            **kwargs,\n            dotenv=dotenv,\n            key=key,\n            secret=secret,\n            url=f\"{url}{name}/two\",\n            to_norming=True,\n        )\n    if second_pass is None or (second_pass[\"analyzed\"] == 0).all():\n        warnings.warn(UserWarning(\"no texts were successfully analyzed in the second pass\"), stacklevel=2)\n    return {\"initial_stats\": status, \"first_pass\": first_pass, \"second_pass\": second_pass}\n</code></pre>"},{"location":"functions/readin_env/","title":"Readin env","text":"<p>Read in a environment variables.</p>"},{"location":"functions/readin_env/#receptiviti.readin_env.readin_env","title":"<code>readin_env(path='.', name='.env', overwrite=False)</code>","text":"<p>Set environment variables from a .env file.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to a .env file, or to a directory containing such a file. By default, this will fall back on <code>~</code> then <code>~/Documents</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'.'</code> </p> <code>name</code> <p>Name of the file, when <code>path</code> points to a directory. By default, this will fall back on <code>.Renviron</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'.env'</code> </p> <code>overwrite</code> <p>If <code>True</code>, overwrites existing environment variables with the same name as those in the .env file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>None</code> <p>If a file is found, it will add contents to <code>os.environ</code>.</p> <p>Examples: <pre><code>receptiviti.readin_env()\n</code></pre></p> Source code in <code>src\\receptiviti\\readin_env.py</code> <pre><code>def readin_env(path=\".\", name=\".env\", overwrite=False) -&gt; None:\n    \"\"\"\n    Set environment variables from a .env file.\n\n    Args:\n      path (str): Path to a .env file, or to a directory containing such a file.\n        By default, this will fall back on `~` then `~/Documents`.\n      name (str): Name of the file, when `path` points to a directory.\n        By default, this will fall back on `.Renviron`.\n      overwrite (bool): If `True`, overwrites existing environment variables with\n        the same name as those in the .env file.\n\n    Returns:\n      If a file is found, it will add contents to `os.environ`.\n\n    Examples:\n    ```python\n    receptiviti.readin_env()\n    ```\n    \"\"\"\n    path = os.path.expanduser(path)\n    envpath = path if os.path.isfile(path) else path + \"/\" + name\n    if os.path.isfile(envpath):\n        ql = re.compile(\"^['\\\"]|['\\\"\\\\s]+$\")\n        with open(envpath, encoding=\"utf-8\") as file:\n            for line in file:\n                entry = line.split(\"=\", 1)\n                if len(entry) == 2 and (overwrite or os.getenv(entry[0]) is None):\n                    os.environ[entry[0]] = ql.sub(\"\", entry[1])\n    elif name != \".Renviron\":\n        readin_env(path, \".Renviron\", overwrite)\n    elif os.path.isfile(os.path.expanduser(\"~/\") + name):\n        readin_env(\"~\", name, overwrite)\n    elif os.path.isfile(os.path.expanduser(\"~/Documents/\") + name):\n        readin_env(\"~/Documents\", name, overwrite)\n</code></pre>"},{"location":"functions/request/","title":"Request","text":"<p>Make requests to the API.</p>"},{"location":"functions/request/#receptiviti.request.request","title":"<code>request(text=None, output=None, ids=None, text_column=None, id_column=None, files=None, directory=None, file_type='txt', encoding=None, return_text=False, context='written', custom_context=False, api_args=None, frameworks=None, framework_prefix=None, bundle_size=1000, bundle_byte_limit=7500000.0, collapse_lines=False, retry_limit=50, clear_cache=False, request_cache=True, cores=1, collect_results=True, in_memory=None, verbose=False, progress_bar=os.getenv('RECEPTIVITI_PB', 'True'), overwrite=False, make_request=True, text_as_paths=False, dotenv=True, cache=os.getenv('RECEPTIVITI_CACHE', ''), cache_degragment=True, cache_overwrite=False, cache_format=os.getenv('RECEPTIVITI_CACHE_FORMAT', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), url=os.getenv('RECEPTIVITI_URL', ''), version=os.getenv('RECEPTIVITI_VERSION', ''), endpoint=os.getenv('RECEPTIVITI_ENDPOINT', ''))</code>","text":"<p>Send texts to be scored by the API.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to be processed, as a string or vector of strings containing the text itself, or the path to a file from which to read in text. If a DataFrame, <code>text_column</code> is used to extract such a vector. A string may also represent a directory in which to search for files. To best ensure paths are not treated as texts, either set <code>text_as_path</code> to <code>True</code>, or use <code>directory</code> to enter a directory path, or <code>files</code> to enter a vector of file paths.</p> <p> TYPE: <code>str | list[str] | DataFrame</code> DEFAULT: <code>None</code> </p> <code>output</code> <p>Path to a file to write results to.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>ids</code> <p>Vector of IDs for each <code>text</code>, or a column name in <code>text</code> containing IDs.</p> <p> TYPE: <code>str | list[str | int]</code> DEFAULT: <code>None</code> </p> <code>text_column</code> <p>Column name in <code>text</code> containing text.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>id_column</code> <p>Column name in <code>text</code> containing IDs.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>files</code> <p>Vector of file paths, as alternate entry to <code>text</code>.</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>directory</code> <p>A directory path to search for files in, as alternate entry to <code>text</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>file_type</code> <p>Extension of the file(s) to be read in from a directory (<code>txt</code> or <code>csv</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'txt'</code> </p> <code>encoding</code> <p>Encoding of file(s) to be read in; one of the standard encodings. If this is <code>None</code> (default), encoding will be predicted for each file, but this can potentially fail, resulting in mis-encoded characters. For best (and fastest) results, specify encoding.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>return_text</code> <p>If <code>True</code>, will include a <code>text</code> column in the output with the original text.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>context</code> <p>Name of the analysis context.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'written'</code> </p> <code>custom_context</code> <p>Name of a custom context (as listed by <code>receptiviti.norming</code>), or <code>True</code> if <code>context</code> is the name of a custom context.</p> <p> TYPE: <code>str | bool</code> DEFAULT: <code>False</code> </p> <code>api_args</code> <p>Additional arguments to include in the request.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>frameworks</code> <p>One or more names of frameworks to request. Note that this changes the results from the API, so it will invalidate any cached results without the same set of frameworks.</p> <p> TYPE: <code>str | list</code> DEFAULT: <code>None</code> </p> <code>framework_prefix</code> <p>If <code>False</code>, will drop framework prefix from column names. If one framework is selected, will default to <code>False</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>bundle_size</code> <p>Maximum number of texts per bundle.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>bundle_byte_limit</code> <p>Maximum byte size of each bundle.</p> <p> TYPE: <code>float</code> DEFAULT: <code>7500000.0</code> </p> <code>collapse_lines</code> <p>If <code>True</code>, will treat files as containing single texts, and collapse multiple lines.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>retry_limit</code> <p>Number of times to retry a failed request.</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> <code>clear_cache</code> <p>If <code>True</code>, will delete the <code>cache</code> before processing.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>request_cache</code> <p>If <code>False</code>, will not temporarily save raw requests for reuse within a day.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>cores</code> <p>Number of CPU cores to use when processing multiple bundles.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>collect_results</code> <p>If <code>False</code>, will not retain bundle results in memory for return.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>in_memory</code> <p>If <code>False</code>, will write bundles to disc, to be loaded when processed. Defaults to <code>True</code> when processing in parallel.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>If <code>True</code>, will print status messages and preserve the progress bar.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>progress_bar</code> <p>If <code>False</code>, will not display a progress bar.</p> <p> TYPE: <code>str | bool</code> DEFAULT: <code>getenv('RECEPTIVITI_PB', 'True')</code> </p> <code>overwrite</code> <p>If <code>True</code>, will overwrite an existing <code>output</code> file.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>text_as_paths</code> <p>If <code>True</code>, will explicitly mark <code>text</code> as a list of file paths. Otherwise, this will be detected.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dotenv</code> <p>Path to a .env file to read environment variables from. By default, will for a file in the current directory or <code>~/Documents</code>. Passed to <code>readin_env</code> as <code>path</code>.</p> <p> TYPE: <code>bool | str</code> DEFAULT: <code>True</code> </p> <code>cache</code> <p>Path to a cache directory, or <code>True</code> to use the default directory. The cache is an Arrow dataset, and so requires the <code>pyarrow</code> package.</p> <p> TYPE: <code>bool | str</code> DEFAULT: <code>getenv('RECEPTIVITI_CACHE', '')</code> </p> <code>cache_degragment</code> <p>If <code>False</code>, will not defragment the cache after writing new results to it.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>cache_overwrite</code> <p>If <code>True</code>, will not check the cache for previously cached texts, but will store results in the cache (unlike <code>cache = False</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>cache_format</code> <p>File format of the cache, of available Arrow formats.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_CACHE_FORMAT', '')</code> </p> <code>key</code> <p>Your API key.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_KEY', '')</code> </p> <code>secret</code> <p>Your API secret.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_SECRET', '')</code> </p> <code>url</code> <p>The URL of the API; defaults to <code>https://api.receptiviti.com</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_URL', '')</code> </p> <code>version</code> <p>Version of the API; defaults to <code>v1</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_VERSION', '')</code> </p> <code>endpoint</code> <p>Endpoint of the API; defaults to <code>framework</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_ENDPOINT', '')</code> </p> RETURNS DESCRIPTION <code>DataFrame | None</code> <p>Scores associated with each input text.</p> <p>Examples:</p> <pre><code># score a single text\nsingle = receptiviti.request(\"a text to score\")\n\n# score multiple texts, and write results to a file\nmulti = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n\n# score texts in separate files\n## defaults to look for .txt files\nfile_results = receptiviti.request(directory = \"./path/to/txt_folder\")\n\n## could be .csv\nfile_results = receptiviti.request(\n    directory = \"./path/to/csv_folder\",\n    text_column = \"text\", file_type = \"csv\"\n)\n\n# score texts in a single file\nresults = receptiviti.request(\"./path/to/file.csv\", text_column = \"text\")\n</code></pre> Request Process <p>This function (along with the internal <code>_manage_request</code> function) handles texts and results in several steps:</p> <ol> <li>Prepare bundles (split <code>text</code> into &lt;= <code>bundle_size</code> and &lt;= <code>bundle_byte_limit</code> bundles).<ol> <li>If <code>text</code> points to a directory or list of files, these will be read in later.</li> <li>If <code>in_memory</code> is <code>False</code>, bundles are written to a temporary location,    and read back in when the request is made.</li> </ol> </li> <li>Get scores for texts within each bundle.<ol> <li>If texts are paths, or <code>in_memory</code> is <code>False</code>, will load texts.</li> <li>If <code>cache</code> is set, will skip any texts with cached scores.</li> <li>If <code>request_cache</code> is <code>True</code>, will check for a cached request.</li> <li>If any texts need scoring and <code>make_request</code> is <code>True</code>, will send unscored texts to the API.</li> </ol> </li> <li>If a request was made and <code>request_cache</code> is set, will cache the response.</li> <li>If <code>cache</code> is set, will write bundle scores to the cache.</li> <li>After requests are made, if <code>cache</code> is set, will defragment the cache    (combine bundle results within partitions).</li> <li>If <code>collect_results</code> is <code>True</code>, will prepare results:<ol> <li>Will realign results with <code>text</code> (and <code>id</code> if provided).</li> <li>If <code>output</code> is specified, will write realigned results to it.</li> <li>Will drop additional columns (such as <code>custom</code> and <code>id</code> if not provided).</li> <li>If <code>framework</code> is specified, will use it to select columns of the results.</li> <li>Returns results.</li> </ol> </li> </ol> Cache <p>If <code>cache</code> is specified, results for unique texts are saved in an Arrow database in the cache location (<code>os.getenv(\"RECEPTIVITI_CACHE\")</code>), and are retrieved with subsequent requests. This ensures that the exact same texts are not re-sent to the API. This does, however, add some processing time and disc space usage.</p> <p>If <code>cache</code> if <code>True</code>, a default directory (<code>receptiviti_cache</code>) will be looked for in the system's temporary directory (<code>tempfile.gettempdir()</code>).</p> <p>The primary cache is checked when each bundle is processed, and existing results are loaded at that time. When processing many bundles in parallel, and many results have been cached, this can cause the system to freeze and potentially crash. To avoid this, limit the number of cores, or disable parallel processing.</p> <p>The <code>cache_format</code> arguments (or the <code>RECEPTIVITI_CACHE_FORMAT</code> environment variable) can be used to adjust the format of the cache.</p> <p>You can use the cache independently with <code>pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))</code>.</p> <p>You can also set the <code>clear_cache</code> argument to <code>True</code> to clear the cache before it is used again, which may be useful if the cache has gotten big, or you know new results will be returned.</p> <p>Even if a cached result exists, it will be reprocessed if it does not have all of the variables of new results, but this depends on there being at least 1 uncached result. If, for instance, you add a framework to your account and want to reprocess a previously processed set of texts, you would need to first clear the cache.</p> <p>Either way, duplicated texts within the same call will only be sent once.</p> <p>The <code>request_cache</code> argument controls a more temporary cache of each bundle request. This is cleared after a day. You might want to set this to <code>False</code> if a new framework becomes available on your account and you want to process a set of text you re-processed recently.</p> <p>Another temporary cache is made when <code>in_memory</code> is <code>False</code>, which is the default when processing in parallel (when there is more than 1 bundle and <code>cores</code> is over 1). This is a temporary directory that contains a file for each unique bundle, which is read in as needed by the parallel workers.</p> Parallelization <p><code>text</code>s are split into bundles based on the <code>bundle_size</code> argument. Each bundle represents a single request to the API, which is why they are limited to 1000 texts and a total size of 10 MB. When there is more than one bundle and <code>cores</code> is greater than 1, bundles are processed by multiple cores.</p> <p>If you have texts spread across multiple files, they can be most efficiently processed in parallel if each file contains a single text (potentially collapsed from multiple lines). If files contain multiple texts (i.e., <code>collapse_lines=False</code>), then texts need to be read in before bundling in order to ensure bundles are under the length limit.</p> <p>If you are calling this function from a script, parallelization will involve rerunning that script in each process, so anything you don't want rerun should be protected by a check that <code>__name__</code> equals <code>\"__main__\"</code> (placed within an <code>if __name__ == \"__main__\":</code> clause).</p> Source code in <code>src\\receptiviti\\request.py</code> <pre><code>def request(\n    text: Union[str, List[str], pandas.DataFrame, None] = None,\n    output: Union[str, None] = None,\n    ids: Union[str, List[str], List[int], None] = None,\n    text_column: Union[str, None] = None,\n    id_column: Union[str, None] = None,\n    files: Union[List[str], None] = None,\n    directory: Union[str, None] = None,\n    file_type: str = \"txt\",\n    encoding: Union[str, None] = None,\n    return_text=False,\n    context=\"written\",\n    custom_context: Union[str, bool] = False,\n    api_args: Union[dict, None] = None,\n    frameworks: Union[str, List[str], None] = None,\n    framework_prefix: Union[bool, None] = None,\n    bundle_size=1000,\n    bundle_byte_limit=75e5,\n    collapse_lines=False,\n    retry_limit=50,\n    clear_cache=False,\n    request_cache=True,\n    cores=1,\n    collect_results=True,\n    in_memory: Union[bool, None] = None,\n    verbose=False,\n    progress_bar: Union[str, bool] = os.getenv(\"RECEPTIVITI_PB\", \"True\"),\n    overwrite=False,\n    make_request=True,\n    text_as_paths=False,\n    dotenv: Union[bool, str] = True,\n    cache: Union[str, bool] = os.getenv(\"RECEPTIVITI_CACHE\", \"\"),\n    cache_degragment=True,\n    cache_overwrite=False,\n    cache_format=os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"\"),\n    key=os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret=os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    url=os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    version=os.getenv(\"RECEPTIVITI_VERSION\", \"\"),\n    endpoint=os.getenv(\"RECEPTIVITI_ENDPOINT\", \"\"),\n) -&gt; pandas.DataFrame | None:\n    \"\"\"\n    Send texts to be scored by the API.\n\n    Args:\n        text (str | list[str] | pandas.DataFrame): Text to be processed, as a string or vector of\n            strings containing the text itself, or the path to a file from which to read in text.\n            If a DataFrame, `text_column` is used to extract such a vector. A string may also\n            represent a directory in which to search for files. To best ensure paths are not\n            treated as texts, either set `text_as_path` to `True`, or use `directory` to enter\n            a directory path, or `files` to enter a vector of file paths.\n        output (str): Path to a file to write results to.\n        ids (str | list[str | int]): Vector of IDs for each `text`, or a column name in `text`\n            containing IDs.\n        text_column (str): Column name in `text` containing text.\n        id_column (str): Column name in `text` containing IDs.\n        files (list[str]): Vector of file paths, as alternate entry to `text`.\n        directory (str): A directory path to search for files in, as alternate entry to `text`.\n        file_type (str): Extension of the file(s) to be read in from a directory (`txt` or `csv`).\n        encoding (str | None): Encoding of file(s) to be read in; one of the\n            [standard encodings](https://docs.python.org/3/library/codecs.html#standard-encodings).\n            If this is `None` (default), encoding will be predicted for each file, but this can\n            potentially fail, resulting in mis-encoded characters. For best (and fastest) results,\n            specify encoding.\n        return_text (bool): If `True`, will include a `text` column in the output with the\n            original text.\n        context (str): Name of the analysis context.\n        custom_context (str | bool): Name of a custom context (as listed by `receptiviti.norming`),\n            or `True` if `context` is the name of a custom context.\n        api_args (dict): Additional arguments to include in the request.\n        frameworks (str | list): One or more names of frameworks to request. Note that this\n            changes the results from the API, so it will invalidate any cached results\n            without the same set of frameworks.\n        framework_prefix (bool): If `False`, will drop framework prefix from column names.\n            If one framework is selected, will default to `False`.\n        bundle_size (int): Maximum number of texts per bundle.\n        bundle_byte_limit (float): Maximum byte size of each bundle.\n        collapse_lines (bool): If `True`, will treat files as containing single texts, and\n            collapse multiple lines.\n        retry_limit (int): Number of times to retry a failed request.\n        clear_cache (bool): If `True`, will delete the `cache` before processing.\n        request_cache (bool): If `False`, will not temporarily save raw requests for reuse\n            within a day.\n        cores (int): Number of CPU cores to use when processing multiple bundles.\n        collect_results (bool): If `False`, will not retain bundle results in memory for return.\n        in_memory (bool | None): If `False`, will write bundles to disc, to be loaded when\n            processed. Defaults to `True` when processing in parallel.\n        verbose (bool): If `True`, will print status messages and preserve the progress bar.\n        progress_bar (str | bool): If `False`, will not display a progress bar.\n        overwrite (bool): If `True`, will overwrite an existing `output` file.\n        text_as_paths (bool): If `True`, will explicitly mark `text` as a list of file paths.\n            Otherwise, this will be detected.\n        dotenv (bool | str): Path to a .env file to read environment variables from. By default,\n            will for a file in the current directory or `~/Documents`.\n            Passed to `readin_env` as `path`.\n        cache (bool | str): Path to a cache directory, or `True` to use the default directory.\n            The cache is an Arrow dataset, and so requires the `pyarrow` package.\n        cache_degragment (bool): If `False`, will not defragment the cache after writing new\n            results to it.\n        cache_overwrite (bool): If `True`, will not check the cache for previously cached texts,\n            but will store results in the cache (unlike `cache = False`).\n        cache_format (str): File format of the cache, of available Arrow formats.\n        key (str): Your API key.\n        secret (str): Your API secret.\n        url (str): The URL of the API; defaults to `https://api.receptiviti.com`.\n        version (str): Version of the API; defaults to `v1`.\n        endpoint (str): Endpoint of the API; defaults to `framework`.\n\n    Returns:\n        Scores associated with each input text.\n\n    Examples:\n        ```python\n        # score a single text\n        single = receptiviti.request(\"a text to score\")\n\n        # score multiple texts, and write results to a file\n        multi = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n\n        # score texts in separate files\n        ## defaults to look for .txt files\n        file_results = receptiviti.request(directory = \"./path/to/txt_folder\")\n\n        ## could be .csv\n        file_results = receptiviti.request(\n            directory = \"./path/to/csv_folder\",\n            text_column = \"text\", file_type = \"csv\"\n        )\n\n        # score texts in a single file\n        results = receptiviti.request(\"./path/to/file.csv\", text_column = \"text\")\n        ```\n\n    Request Process:\n        This function (along with the internal `_manage_request` function) handles texts and results in several steps:\n\n        1. Prepare bundles (split `text` into &lt;= `bundle_size` and &lt;= `bundle_byte_limit` bundles).\n            1. If `text` points to a directory or list of files, these will be read in later.\n            2. If `in_memory` is `False`, bundles are written to a temporary location,\n               and read back in when the request is made.\n        2. Get scores for texts within each bundle.\n            1. If texts are paths, or `in_memory` is `False`, will load texts.\n            2. If `cache` is set, will skip any texts with cached scores.\n            3. If `request_cache` is `True`, will check for a cached request.\n            4. If any texts need scoring and `make_request` is `True`, will send unscored texts to the API.\n        3. If a request was made and `request_cache` is set, will cache the response.\n        4. If `cache` is set, will write bundle scores to the cache.\n        5. After requests are made, if `cache` is set, will defragment the cache\n           (combine bundle results within partitions).\n        6. If `collect_results` is `True`, will prepare results:\n            1. Will realign results with `text` (and `id` if provided).\n            2. If `output` is specified, will write realigned results to it.\n            3. Will drop additional columns (such as `custom` and `id` if not provided).\n            4. If `framework` is specified, will use it to select columns of the results.\n            5. Returns results.\n\n    Cache:\n        If `cache` is specified, results for unique texts are saved in an Arrow database\n        in the cache location (`os.getenv(\"RECEPTIVITI_CACHE\")`), and are retrieved with\n        subsequent requests. This ensures that the exact same texts are not re-sent to the API.\n        This does, however, add some processing time and disc space usage.\n\n        If `cache` if `True`, a default directory (`receptiviti_cache`) will be\n        looked for in the system's temporary directory (`tempfile.gettempdir()`).\n\n        The primary cache is checked when each bundle is processed, and existing results are\n        loaded at that time. When processing many bundles in parallel, and many results have\n        been cached, this can cause the system to freeze and potentially crash.\n        To avoid this, limit the number of cores, or disable parallel processing.\n\n        The `cache_format` arguments (or the `RECEPTIVITI_CACHE_FORMAT` environment variable) can be\n        used to adjust the format of the cache.\n\n        You can use the cache independently with\n        `pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))`.\n\n        You can also set the `clear_cache` argument to `True` to clear the cache before it is used\n        again, which may be useful if the cache has gotten big, or you know new results will be\n        returned.\n\n        Even if a cached result exists, it will be reprocessed if it does not have all of the\n        variables of new results, but this depends on there being at least 1 uncached result. If,\n        for instance, you add a framework to your account and want to reprocess a previously\n        processed set of texts, you would need to first clear the cache.\n\n        Either way, duplicated texts within the same call will only be sent once.\n\n        The `request_cache` argument controls a more temporary cache of each bundle request. This\n        is cleared after a day. You might want to set this to `False` if a new framework becomes\n        available on your account and you want to process a set of text you re-processed recently.\n\n        Another temporary cache is made when `in_memory` is `False`, which is the default when\n        processing in parallel (when there is more than 1 bundle and `cores` is over 1). This is a\n        temporary directory that contains a file for each unique bundle, which is read in as needed\n        by the parallel workers.\n\n    Parallelization:\n        `text`s are split into bundles based on the `bundle_size` argument. Each bundle represents\n        a single request to the API, which is why they are limited to 1000 texts and a total size\n        of 10 MB. When there is more than one bundle and `cores` is greater than 1, bundles are\n        processed by multiple cores.\n\n        If you have texts spread across multiple files, they can be most efficiently processed in\n        parallel if each file contains a single text (potentially collapsed from multiple lines).\n        If files contain multiple texts (i.e., `collapse_lines=False`), then texts need to be\n        read in before bundling in order to ensure bundles are under the length limit.\n\n        If you are calling this function from a script, parallelization will involve rerunning\n        that script in each process, so anything you don't want rerun should be protected by\n        a check that `__name__` equals `\"__main__\"`\n        (placed within an `if __name__ == \"__main__\":` clause).\n    \"\"\"\n    if cores &gt; 1 and current_process().name != \"MainProcess\":\n        return None\n    if output is not None and os.path.isfile(output) and not overwrite:\n        msg = \"`output` file already exists; use `overwrite=True` to overwrite it\"\n        raise RuntimeError(msg)\n    start_time = perf_counter()\n\n    if dotenv:\n        readin_env(dotenv if isinstance(dotenv, str) else \".\")\n        dotenv = False\n\n    # check norming context\n    if isinstance(custom_context, str):\n        context = custom_context\n        custom_context = True\n    if context != \"written\":\n        if verbose:\n            print(f\"retrieving norming contexts ({perf_counter() - start_time:.4f})\")\n        available_contexts: List[str] = norming(name_only=True, url=url, key=key, secret=secret, verbose=False)\n        if (\"custom/\" + context if custom_context else context) not in available_contexts:\n            msg = f\"norming context {context} is not on record or is not completed\"\n            raise RuntimeError(msg)\n\n    # check frameworks\n    if frameworks and version and \"2\" in version:\n        if not api_args:\n            api_args = {}\n        if isinstance(frameworks, str):\n            frameworks = [frameworks]\n        api_args[\"frameworks\"] = [f for f in frameworks if f != \"summary\"]\n    if api_args and \"frameworks\" in api_args:\n        arg_frameworks: List[str] = (\n            api_args[\"frameworks\"].split(\",\") if isinstance(api_args[\"frameworks\"], str) else api_args[\"frameworks\"]\n        )\n        available_frameworks = get_frameworks(url=url, key=key, secret=secret)\n        for f in arg_frameworks:\n            if f not in available_frameworks:\n                msg = f\"requested framework is not available to your account: {f}\"\n                raise RuntimeError(msg)\n        if isinstance(api_args[\"frameworks\"], list):\n            api_args[\"frameworks\"] = \",\".join(api_args[\"frameworks\"])\n\n    if isinstance(cache, str) and cache:\n        if find_spec(\"pyarrow\") is None:\n            msg = \"install the `pyarrow` package to use the cache\"\n            raise RuntimeError(msg)\n        if clear_cache and os.path.exists(cache):\n            shutil.rmtree(cache, True)\n        os.makedirs(cache, exist_ok=True)\n        if not cache_format:\n            cache_format = os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"parquet\")\n        if cache_format not in [\"parquet\", \"feather\"]:\n            msg = \"`cache_format` must be `parquet` or `feather`\"\n            raise RuntimeError(msg)\n    else:\n        cache = \"\"\n\n    data, res, id_specified = _manage_request(\n        text=text,\n        ids=ids,\n        text_column=text_column,\n        id_column=id_column,\n        files=files,\n        directory=directory,\n        file_type=file_type,\n        encoding=encoding,\n        context=f\"custom/{context}\" if custom_context else context,\n        api_args=api_args,\n        bundle_size=bundle_size,\n        bundle_byte_limit=bundle_byte_limit,\n        collapse_lines=collapse_lines,\n        retry_limit=retry_limit,\n        request_cache=request_cache,\n        cores=cores,\n        collect_results=collect_results,\n        in_memory=in_memory,\n        verbose=verbose,\n        progress_bar=progress_bar,\n        make_request=make_request,\n        text_as_paths=text_as_paths,\n        dotenv=dotenv,\n        cache=cache,\n        cache_overwrite=cache_overwrite,\n        cache_format=cache_format,\n        key=key,\n        secret=secret,\n        url=url,\n        version=version,\n        endpoint=endpoint,\n    )\n\n    # finalize\n    if collect_results and (res is None or not res.shape[0]):\n        msg = \"no results\"\n        raise RuntimeError(msg)\n    if cache and cache_degragment:\n        writer = _get_writer(cache_format)\n        for bin_dir in glob(cache + \"/bin=*/\"):\n            _defragment_bin(bin_dir, cache_format, writer)\n    if not collect_results:\n        if verbose:\n            print(f\"done ({perf_counter() - start_time:.4f})\")\n        return None\n    if verbose:\n        print(f\"preparing output ({perf_counter() - start_time:.4f})\")\n    data.set_index(\"id\", inplace=True)\n    res.set_index(\"id\", inplace=True)\n    if len(res) != len(data):\n        res = res.join(data[\"text\"])\n        data_absent = data.loc[list(set(data.index).difference(res.index))]\n        data_absent = data_absent.loc[data_absent[\"text\"].isin(res[\"text\"])]\n        if data.size:\n            res = res.reset_index()\n            res.set_index(\"text\", inplace=True)\n            data_dupes = res.loc[data_absent[\"text\"]]\n            data_dupes[\"id\"] = data_absent.index.to_list()\n            res = pandas.concat([res, data_dupes])\n            res.reset_index(inplace=True, drop=True)\n            res.set_index(\"id\", inplace=True)\n    res = res.join(data[\"text\"], how=\"right\")\n    if not return_text:\n        res.drop(\"text\", axis=1, inplace=True)\n    res = res.reset_index()\n\n    if output is not None:\n        if verbose:\n            print(f\"writing results to file: {output} ({perf_counter() - start_time:.4f})\")\n        res.to_csv(output, index=False)\n\n    drops = [\"custom\", \"bin\"]\n    if not id_specified:\n        drops.append(\"id\")\n    res.drop(\n        list({*drops}.intersection(res.columns)),\n        axis=\"columns\",\n        inplace=True,\n    )\n    if frameworks is not None:\n        if verbose:\n            print(f\"selecting frameworks ({perf_counter() - start_time:.4f})\")\n        if isinstance(frameworks, str):\n            frameworks = [frameworks]\n        if len(frameworks) == 1 and framework_prefix is None:\n            framework_prefix = False\n        select = []\n        if id_specified:\n            select.append(\"id\")\n        if return_text:\n            select.append(\"text\")\n        select.append(\"text_hash\")\n        res = res.filter(regex=f\"^(?:{'|'.join(select + frameworks)})(?:$|\\\\.)\")\n    if isinstance(framework_prefix, bool) and not framework_prefix:\n        prefix_pattern = re.compile(\"^[^.]+\\\\.\")\n        res.columns = pandas.Index([prefix_pattern.sub(\"\", col) for col in res.columns])\n\n    if verbose:\n        print(f\"done ({perf_counter() - start_time:.4f})\")\n\n    return res\n</code></pre>"},{"location":"functions/status/","title":"Status","text":"<p>Check the status of the API.</p>"},{"location":"functions/status/#receptiviti.status.status","title":"<code>status(url=os.getenv('RECEPTIVITI_URL', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), dotenv=False, verbose=True)</code>","text":"<p>Check the API's status.</p> <p>Ping the Receptiviti API to see if it's available, and if your credentials are valid.</p> PARAMETER DESCRIPTION <code>url</code> <p>The URL of the API.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_URL', '')</code> </p> <code>key</code> <p>Your API key.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_KEY', '')</code> </p> <code>secret</code> <p>Your API secret.</p> <p> TYPE: <code>str</code> DEFAULT: <code>getenv('RECEPTIVITI_SECRET', '')</code> </p> <code>dotenv</code> <p>Path to a .env file to read environment variables from, or <code>True</code> to look for a file in the current directory.</p> <p> TYPE: <code>bool | str</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>If <code>False</code>, will not print status messages.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Union[Response, None]</code> <p>Response from the API server.</p> <p>Examples:</p> <pre><code>receptiviti.status()\n</code></pre> Source code in <code>src\\receptiviti\\status.py</code> <pre><code>def status(\n    url: str = os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    key: str = os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret: str = os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    dotenv: Union[bool, str] = False,\n    verbose=True,\n) -&gt; Union[requests.Response, None]:\n    \"\"\"\n    Check the API's status.\n\n    Ping the Receptiviti API to see if it's available, and if your credentials are valid.\n\n    Args:\n      url (str): The URL of the API.\n      key (str): Your API key.\n      secret (str): Your API secret.\n      dotenv (bool | str): Path to a .env file to read environment variables from, or `True`\n        to look for a file in the current directory.\n      verbose (bool): If `False`, will not print status messages.\n\n    Returns:\n      Response from the API server.\n\n    Examples:\n        ```python\n        receptiviti.status()\n        ```\n    \"\"\"\n    _, url, key, secret = _resolve_request_def(url, key, secret, dotenv)\n    try:\n        res = requests.get(url.lower() + \"/v1/ping\", auth=(key, secret), timeout=9999)\n    except requests.exceptions.RequestException:\n        if verbose:\n            print(\"Status: ERROR\\nMessage: URL is unreachable\")\n        return None\n    content = res.json() if res.text[:1] == \"{\" else {\"message\": res.text}\n    if verbose:\n        print(\"Status: \" + (\"OK\" if res.status_code == 200 else \"ERROR\"))\n        print(\n            \"Message: \"\n            + (\n                str(res.status_code)\n                + (\" (\" + str(content[\"code\"]) + \")\" if \"code\" in content else \"\")\n                + \": \"\n                + content[\"pong\" if \"pong\" in content else \"message\"]\n            )\n        )\n    return res\n</code></pre>"}]}