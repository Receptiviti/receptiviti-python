{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A Python package to process text with the Receptiviti API.</p>"},{"location":"#installation","title":"Installation","text":"<p>If needed, download Python from python.org, then install the package with pip:</p> <pre><code>pip install git+https://github.com/miserman/receptiviti-py.git\n</code></pre> <p>And load the package in a python console:</p> <pre><code>import receptiviti\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<pre><code># score a single text\nsingle = receptiviti.request(\"a text to score\")\n# score multiple texts, and write results to a file\nmulti = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n# score texts in separate files\n## defaults to look for .txt files\nfile_results = receptiviti.request(\"./path/to/txt_folder\")\n## could be .csv\nfile_results = receptiviti.request(\n\"./path/to/csv_folder\",\ntext_column = \"text\", file_type = \"csv\"\n)\n# score texts in a single file\nresults = receptiviti.request(\"./path/to/file.csv\", text_column = \"text\")\n</code></pre>"},{"location":"#api-access","title":"API Access","text":"<p>To access the API, you will need to load your key and secret, as found on your dashboard.</p> <p>You can enter these as arguments in each function call, but by default they will be looked for in these environment variables:</p> <pre><code>RECEPTIVITI_KEY=\"32lettersandnumbers\"\nRECEPTIVITI_SECRET=\"56LettersAndNumbers\"\n</code></pre> <p>You can store these in a <code>.env</code> (in the current directory or <code>~/Documents</code>) file permanently:</p> <pre><code># use the `dotenv` argument\nreceptiviti.status(dotenv=True)\n# or load variables in beforehand\nreceptiviti.readin_env()\n</code></pre> <p>Or set them temporarily:</p> <pre><code>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</code></pre>"},{"location":"articles/quick_start/","title":"Get Started","text":"In\u00a0[2]: Copied! <pre>import receptiviti\n</pre> import receptiviti In\u00a0[3]: Copied! <pre>receptiviti.status()\n</pre> receptiviti.status() <pre>Status: OK\nMessage: 200: Hello there, World!\n</pre> Out[3]: <pre>&lt;Response [200]&gt;</pre> <p>If your credentials are not recognized, you'll get a response like this:</p> In\u00a0[4]: Copied! <pre>receptiviti.status(key=123, secret=123)\n</pre> receptiviti.status(key=123, secret=123) <pre>Status: ERROR\nMessage: 401 (1411): Unrecognized API key pair. This call will not count towards your plan.\n</pre> Out[4]: <pre>&lt;Response [401]&gt;</pre> In\u00a0[5]: Copied! <pre>results = receptiviti.request(\"texts to score\")\n</pre> results = receptiviti.request(\"texts to score\") <pre>                                                                                         \r</pre> <p>Or a character vector:</p> In\u00a0[6]: Copied! <pre>results = receptiviti.request([\"text one\", \"text two\"])\n</pre> results = receptiviti.request([\"text one\", \"text two\"]) <pre>                                                                                         \r</pre> <p>Or from a <code>DataFrame</code>:</p> In\u00a0[7]: Copied! <pre>import pandas\ndata = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})\n\n# directly\nresults = receptiviti.request(data[\"text\"])\n\n# by column name\nresults = receptiviti.request(data, text_column=\"text\")\n</pre> import pandas data = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})  # directly results = receptiviti.request(data[\"text\"])  # by column name results = receptiviti.request(data, text_column=\"text\") <pre>                                                                                         \r</pre> In\u00a0[8]: Copied! <pre># single\nresults = receptiviti.request(\"../files/file.txt\")\n\n# multiple\nresults = receptiviti.request([\"../files/file1.txt\", \"../files/file2.txt\"])\n</pre> # single results = receptiviti.request(\"../files/file.txt\")  # multiple results = receptiviti.request([\"../files/file1.txt\", \"../files/file2.txt\"]) <pre>                                                                                         \r</pre> <p>Or to a comma delimited file with a column containing text. Here, the <code>text_column</code> argument specifies which column contains text:</p> In\u00a0[9]: Copied! <pre># single\nresults = receptiviti.request(\"../files/file.csv\", text_column=\"text\")\n\n# multiple\nresults = receptiviti.request(\n  [\"../files/file1.csv\", \"../files/file2.csv\"],\n  text_column=\"text\"\n)\n</pre> # single results = receptiviti.request(\"../files/file.csv\", text_column=\"text\")  # multiple results = receptiviti.request(   [\"../files/file1.csv\", \"../files/file2.csv\"],   text_column=\"text\" ) <pre>                                                                                         \r</pre> <p>Or you can point to a directory containing text files:</p> In\u00a0[10]: Copied! <pre>results = receptiviti.request(\"../files\")\n</pre> results = receptiviti.request(\"../files\") <pre>                                                                                         \r</pre> <p>By default <code>.txt</code> files will be looked for, but you can specify <code>.csv</code> files with the <code>file_type</code> argument:</p> In\u00a0[11]: Copied! <pre>results = receptiviti.request(\n  \"../files\",\n  text_column=\"text\", file_type=\"csv\"\n)\n</pre> results = receptiviti.request(   \"../files\",   text_column=\"text\", file_type=\"csv\" ) <pre>                                                                                         \r</pre> In\u00a0[12]: Copied! <pre>results = receptiviti.request(\"texts to score\")\nresults.iloc[:, :3]\n</pre> results = receptiviti.request(\"texts to score\") results.iloc[:, :3] <pre>                                                                                         \r</pre> Out[12]: text_hash summary.word_count summary.words_per_sentence 0 acab8277267d0efee0828f94e0919ddf 3 3.0 <p>Here, the first column (<code>text_hash</code>) is the MD5 hash of the text, which identifies unique texts, and is stored in the main cache.</p> <p>The entered text can also be included with the <code>return_text</code> argument:</p> In\u00a0[13]: Copied! <pre>results = receptiviti.request(\"texts to score\", return_text=True)\nresults[[\"text_hash\", \"text\"]]\n</pre> results = receptiviti.request(\"texts to score\", return_text=True) results[[\"text_hash\", \"text\"]] <pre>                                                                                         \r</pre> Out[13]: text_hash text 0 acab8277267d0efee0828f94e0919ddf texts to score <p>You can also select frameworks before they are all returned:</p> In\u00a0[14]: Copied! <pre>results = receptiviti.request(\"texts to score\", frameworks=\"liwc\")\nresults.iloc[:, :5]\n</pre> results = receptiviti.request(\"texts to score\", frameworks=\"liwc\") results.iloc[:, :5] <pre>                                                                                         \r</pre> Out[14]: text_hash analytical_thinking clout authentic emotional_tone 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 0.257742 <p>By default, a single framework will have column names without the framework name, but you can retain these with <code>framework_prefix=True</code>:</p> In\u00a0[15]: Copied! <pre>results = receptiviti.request(\n  \"texts to score\",\n  frameworks=\"liwc\", framework_prefix=True\n)\nresults.iloc[:, :4]\n</pre> results = receptiviti.request(   \"texts to score\",   frameworks=\"liwc\", framework_prefix=True ) results.iloc[:, :4] <pre>                                                                                         \r</pre> Out[15]: text_hash liwc.analytical_thinking liwc.clout liwc.authentic 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 In\u00a0[16]: Copied! <pre>data = pandas.DataFrame({\n  \"id\": [1, 2, 3, 4],\n  \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"]\n})\nresults = receptiviti.request(data[\"text\"])\n\n# combine data and results\ndata.join(results).iloc[:, :5]\n</pre> data = pandas.DataFrame({   \"id\": [1, 2, 3, 4],   \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"] }) results = receptiviti.request(data[\"text\"])  # combine data and results data.join(results).iloc[:, :5] <pre>                                                                                         \r</pre> Out[16]: id text text_hash summary.word_count summary.words_per_sentence 0 1 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 1 2 NaN NaN NaN NaN 2 3 NaN NaN NaN 3 4 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 <p>You can also provide a vector of unique IDs to be returned with results so they can be merged with other data:</p> In\u00a0[17]: Copied! <pre>results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"])\nresults.iloc[:, :4]\n</pre> results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"]) results.iloc[:, :4] <pre>                                                                                         \r</pre> Out[17]: id text_hash summary.word_count summary.words_per_sentence 0 a 42ff59040f004970040f90a19aa6b3fa 2 2.0 1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2.0 In\u00a0[18]: Copied! <pre># merge with a new dataset\ndata = pandas.DataFrame({\n  \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],\n  \"type\": [\"a\", \"b\", \"a\", \"b\"]\n})\ndata.join(results.set_index(\"id\"), \"type\").iloc[:, :5]\n</pre> # merge with a new dataset data = pandas.DataFrame({   \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],   \"type\": [\"a\", \"b\", \"a\", \"b\"] }) data.join(results.set_index(\"id\"), \"type\").iloc[:, :5] Out[18]: id type text_hash summary.word_count summary.words_per_sentence 0 a1 a 42ff59040f004970040f90a19aa6b3fa 2 2.0 1 b1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2.0 2 a2 a 42ff59040f004970040f90a19aa6b3fa 2 2.0 3 b2 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2.0 In\u00a0[19]: Copied! <pre>receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True)\nresults = pandas.read_csv(\"~/Documents/results.csv\")\nresults.iloc[:, :4]\n</pre> receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True) results = pandas.read_csv(\"~/Documents/results.csv\") results.iloc[:, :4] <pre>                                                                                         \r</pre> Out[19]: id text_hash summary.word_count summary.words_per_sentence 0 1 acab8277267d0efee0828f94e0919ddf 3 3.0"},{"location":"articles/quick_start/#install-and-load","title":"Install and Load\u00b6","text":"<p>First, download and install Python from python.org.</p> <p>Then, install the package:</p> <pre>pip install git+https://github.com/miserman/receptiviti-py.git\n</pre> <p>Each time you start a Python session, load the package:</p>"},{"location":"articles/quick_start/#set-up-api-credentials","title":"Set Up API Credentials\u00b6","text":"<p>You can find your API key and secret on your dashboard.</p> <p>You can set these credentials up in Python permanently or temporarily:</p>"},{"location":"articles/quick_start/#permanent","title":"Permanent\u00b6","text":"<p>Open or create a <code>~/.env</code> file, Then add these environment variables with your key and secret:</p> <pre>RECEPTIVITI_KEY=\"\"\nRECEPTIVITI_SECRET=\"\"\n</pre> <p>These can be read in with the <code>receptiviti.readin_env()</code> function, which is automatically called if credentials are not otherwise provided (and the <code>dotenv</code> argument is <code>True</code>).</p>"},{"location":"articles/quick_start/#temporary","title":"Temporary\u00b6","text":"<p>Add your key and secret, and run at the start of each session:</p> <pre>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</pre>"},{"location":"articles/quick_start/#confirm-credentials","title":"Confirm Credentials\u00b6","text":"<p>Check that the API is reachable, and your credentials are recognized:</p>"},{"location":"articles/quick_start/#enter-your-text","title":"Enter Your Text\u00b6","text":""},{"location":"articles/quick_start/#loaded-text","title":"Loaded Text\u00b6","text":"<p>If your texts are already in Python, you can enter them directly.</p> <p>These can be in a single character:</p>"},{"location":"articles/quick_start/#text-in-files","title":"Text in files\u00b6","text":"<p>You can enter paths to files containing separate texts in each line:</p>"},{"location":"articles/quick_start/#use-results","title":"Use Results\u00b6","text":""},{"location":"articles/quick_start/#returned-results","title":"Returned Results\u00b6","text":"<p>Results are returned as a <code>DataFrame</code>, with a row for each text, and columns for each framework variable:</p>"},{"location":"articles/quick_start/#aligning-results","title":"Aligning Results\u00b6","text":"<p>Results are returned in a way that aligns with the text you enter originally, including any duplicates or invalid entries.</p> <p>This means you can add the results object to original data:</p>"},{"location":"articles/quick_start/#saved-results","title":"Saved Results\u00b6","text":"<p>Results can also be saved to a <code>.csv</code> file:</p>"},{"location":"articles/quick_start/#preserving-results","title":"Preserving Results\u00b6","text":"<p>The <code>receptiviti.request</code> function tries to avoid sending texts to the API as much as possible:</p> <ul> <li>As part of the preparation process, it excludes duplicates and invalid texts.</li> <li>It checks the primary cache to see if any texts have already been scored.<ul> <li>The primary cache is an Arrow database located by the <code>cache</code> augment.</li> <li>Its format is determined by <code>cache_format</code>.</li> <li>You can skip checking it initially while still writing results to it with <code>cache_overwrite=True</code>.</li> <li>It can be cleared with <code>clear_cache=True</code>.</li> </ul> </li> <li>It will check for any responses to previous, identical requests.<ul> <li>Responses are stored in the <code>receptiviti_request_cache</code> directory of your system's temporary directory (<code>tempfile.gettempdir()</code>).</li> <li>You can avoid using this cache with <code>request_cache=False</code>.</li> <li>This cache is cleared after a day.</li> </ul> </li> </ul> <p>If you want to make sure no texts are sent to the API, you can use <code>make_request=False</code>. This will use the primary and request cache, but will fail if any texts are not found there.</p> <p>If a call fails before results can be written to the cache or returned, all received responses will still be in the request cache, but those will be deleted after a day.</p>"},{"location":"articles/quick_start/#handling-big-data","title":"Handling Big Data\u00b6","text":"<p>The <code>receptiviti</code> function will handle splitting texts into bundles, so the limit on how many texts you can process at once will come down to your system's amount of random access memory (RAM). Several thousands of texts should be fine, but getting into millions of texts, you may not be able to have all of the results loaded at once. To get around this, you can fully process subsets of your texts.</p> <p>A benefit of processing more texts at once is that requests can be parallelized, but this is more RAM intensive, and the primary cache is updated less frequently (as it is updated only at the end of a complete run).</p> <p>You could also parallelize your own batches, but be sure to set <code>cores</code> to <code>1</code> (to disable the function's parallelization) and <code>cache</code> to <code>False</code> (to avoid attempting to read from the cache while it is being written to by another instance).</p> <p>Disabling the cache is also more efficient, but you may want to ensure you are not sending duplicate texts between calls. The function handles duplicate texts within calls (only ever sending unique texts), but depends on the cache to avoid sending duplicates between calls.</p>"},{"location":"functions/readin_env/","title":"Readin env","text":"<p>Read in a environment variables.</p>"},{"location":"functions/readin_env/#receptiviti.readin_env.readin_env","title":"<code>readin_env(path='.', name='.env', overwrite=False)</code>","text":"<p>Set environment variables from a .env file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to a .env file, or to a directory containing such a file. By default, this will fall back on <code>~/Documents</code>.</p> <code>'.'</code> <code>name</code> <code>str</code> <p>Name of the file, when <code>path</code> points to a directory. By default, this will fall back on <code>.Renviron</code>.</p> <code>'.env'</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, overwrites existing environment variables with the same name as those in the .env file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>If a file is found, it will add contents to <code>os.environ</code>.</p> Source code in <code>src\\receptiviti\\readin_env.py</code> <pre><code>def readin_env(path=\".\", name=\".env\", overwrite=False) -&gt; None:\n\"\"\"\n    Set environment variables from a .env file.\n    Args:\n      path (str): Path to a .env file, or to a directory containing such a file.\n        By default, this will fall back on `~/Documents`.\n      name (str): Name of the file, when `path` points to a directory.\n        By default, this will fall back on `.Renviron`.\n      overwrite (bool): If `True`, overwrites existing environment variables with\n        the same name as those in the .env file.\n    Returns:\n      If a file is found, it will add contents to `os.environ`.\n    \"\"\"\npath = os.path.expanduser(path)\nenvpath = path if os.path.isfile(path) else path + \"/\" + name\nif os.path.isfile(envpath):\nql = re.compile(\"^['\\\"]|['\\\"\\\\s]+$\")\nwith open(envpath, encoding=\"utf-8\") as file:\nfor line in file:\nentry = line.split(\"=\", 1)\nif len(entry) == 2 and (overwrite or os.getenv(entry[0]) is None):\nos.environ[entry[0]] = ql.sub(\"\", entry[1])\nelif name != \".Renviron\":\nreadin_env(path, \".Renviron\", overwrite)\nelif path != os.path.expanduser(\"~/Documents\"):\nreadin_env(\"~/Documents\", name, overwrite)\n</code></pre>"},{"location":"functions/request/","title":"Request","text":"<p>Make requests to the API.</p>"},{"location":"functions/request/#receptiviti.request.request","title":"<code>request(text, output=None, ids=None, text_column=None, id_column=None, file_type='txt', return_text=False, api_args=None, frameworks=None, framework_prefix=None, bundle_size=1000, bundle_byte_limit=7500000.0, collapse_lines=False, retry_limit=50, clear_cache=False, request_cache=True, cores=cpu_count() - 2, in_memory=None, verbose=False, progress_bar=True, overwrite=False, make_request=True, text_as_paths=False, dotenv=True, cache=os.getenv('RECEPTIVITI_CACHE', ''), cache_overwrite=False, cache_format=os.getenv('RECEPTIVITI_CACHE_FORMAT', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), url=os.getenv('RECEPTIVITI_URL', ''), version=os.getenv('RECEPTIVITI_VERSION', ''), endpoint=os.getenv('RECEPTIVITI_ENDPOINT', ''))</code>","text":"<p>Send texts to be scored by the API.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list | DataFrame</code> <p>Text to be processed.</p> required <code>output</code> <code>str</code> <p>Path to a file to write results to.</p> <code>None</code> <code>ids</code> <code>str | list</code> <p>Vector of IDs for each <code>text</code>, or a column name in <code>text</code> containing IDs.</p> <code>None</code> <code>text_column</code> <code>str</code> <p>Column name in <code>text</code> containing text.</p> <code>None</code> <code>id_column</code> <code>str</code> <p>Column name in <code>text</code> containing IDs.</p> <code>None</code> <code>file_type</code> <code>str</code> <p>Extension of the file(s) to be read in from a directory (<code>txt</code> or <code>csv</code>).</p> <code>'txt'</code> <code>return_text</code> <code>bool</code> <p>If <code>True</code>, will include a <code>text</code> column in the output with the original text.</p> <code>False</code> <code>api_args</code> <code>dict</code> <p>Additional arguments to include in the request.</p> <code>None</code> <code>frameworks</code> <code>str | list</code> <p>One or more names of frameworks to return.</p> <code>None</code> <code>framework_prefix</code> <code>bool</code> <p>If <code>False</code>, will drop framework prefix from column names. If one framework is selected, will default to <code>False</code>.</p> <code>None</code> <code>bundle_size</code> <code>int</code> <p>Maximum number of texts per bundle.</p> <code>1000</code> <code>bundle_byte_limit</code> <code>float</code> <p>Maximum byte size of each bundle.</p> <code>7500000.0</code> <code>collapse_lines</code> <code>bool</code> <p>If <code>True</code>, will treat files as containing single texts, and collapse multiple lines.</p> <code>False</code> <code>retry_limit</code> <code>int</code> <p>Number of times to retry a failed request.</p> <code>50</code> <code>clear_cache</code> <code>bool</code> <p>If <code>True</code>, will delete the <code>cache</code> before processing.</p> <code>False</code> <code>request_cache</code> <code>bool</code> <p>If <code>False</code>, will not temporarily save raw requests for reuse within a day.</p> <code>True</code> <code>cores</code> <code>int</code> <p>Number of CPU cores to use when processing multiple bundles.</p> <code>cpu_count() - 2</code> <code>in_memory</code> <code>bool | None</code> <p>If <code>False</code>, will write bundles to disc, to be loaded when processed. Defaults to <code>True</code> when processing in parallel.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, will print status messages and preserve the progress bar.</p> <code>False</code> <code>progress_bar</code> <code>bool</code> <p>If <code>False</code>, will not display a progress bar.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, will overwrite an existing <code>output</code> file.</p> <code>False</code> <code>text_as_paths</code> <code>bool</code> <p>If <code>True</code>, will explicitly mark <code>text</code> as a list of file paths. Otherwise, this will be detected.</p> <code>False</code> <code>dotenv</code> <code>bool | str</code> <p>Path to a .env file to read environment variables from. By default, will for a file in the current directory or <code>~/Documents</code>. Passed to <code>readin_env</code> as <code>path</code>.</p> <code>True</code> <code>cache</code> <code>bool | str</code> <p>Path to a cache directory, <code>True</code> or <code>\"\"</code> to use the default directory, or <code>False</code> to not use a cache.</p> <code>os.getenv('RECEPTIVITI_CACHE', '')</code> <code>cache_overwrite</code> <code>bool</code> <p>If <code>True</code>, will not check the cache for previously cached texts, but will store results in the cache (unlike <code>cache = False</code>).</p> <code>False</code> <code>cache_format</code> <code>str</code> <p>File format of the cache, of available Arrow formats.</p> <code>os.getenv('RECEPTIVITI_CACHE_FORMAT', '')</code> <code>key</code> <code>str</code> <p>Your API key.</p> <code>os.getenv('RECEPTIVITI_KEY', '')</code> <code>secret</code> <code>str</code> <p>Your API secret.</p> <code>os.getenv('RECEPTIVITI_SECRET', '')</code> <code>url</code> <code>str</code> <p>The URL of the API; defaults to <code>https://api.receptiviti.com</code>.</p> <code>os.getenv('RECEPTIVITI_URL', '')</code> <code>version</code> <code>str</code> <p>Version of the API; defaults to <code>v1</code>.</p> <code>os.getenv('RECEPTIVITI_VERSION', '')</code> <code>endpoint</code> <code>str</code> <p>Endpoint of the API; defaults to fefe <code>framework</code>.</p> <code>os.getenv('RECEPTIVITI_ENDPOINT', '')</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Scores associated with each input text.</p> Cache <p>By default, results for unique texts are saved in an Arrow database in the cache location (<code>os.getenv(\"RECEPTIVITI_CACHE\")</code>), and are retrieved with subsequent requests. This ensures that the exact same texts are not re-sent to the API. This does, however, add some processing time and disc space usage.</p> <p>If a cache location is not specified, a default directory (<code>receptiviti_cache</code>) will be looked for in the system's temporary directory (<code>tempfile.gettempdir()</code>).</p> <p>The <code>cache_format</code> arguments (or the <code>RECEPTIVITI_CACHE_FORMAT</code> environment variable) can be used to adjust the format of the cache.</p> <p>You can use the cache independently with <code>pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))</code>.</p> <p>You can set the <code>cache</code> argument to <code>False</code> to prevent the cache from being used, which might make sense if you don't expect to need to reprocess texts.</p> <p>You can also set the <code>clear_cache</code> argument to <code>True</code> to clear the cache before it is used again, which may be useful if the cache has gotten big, or you know new results will be returned.</p> <p>Even if a cached result exists, it will be reprocessed if it does not have all of the variables of new results, but this depends on there being at least 1 uncached result. If, for instance, you add a framework to your account and want to reprocess a previously processed set of texts, you would need to first clear the cache.</p> <p>Either way, duplicated texts within the same call will only be sent once.</p> <p>The <code>request_cache</code> argument controls a more temporary cache of each bundle request. This is cleared after a day. You might want to set this to <code>False</code> if a new framework becomes available on your account and you want to process a set of text you re-processed recently.</p> <p>Another temporary cache is made when <code>in_memory</code> is <code>False</code>, which is the default when processing in parallel (when there is more than 1 bundle and <code>cores</code> is over 1). This is a temporary directory that contains a file for each unique bundle, which is read in as needed by the parallel workers.</p> Parallelization <p><code>text</code>s are split into bundles based on the <code>bundle_size</code> argument. Each bundle represents a single request to the API, which is why they are limited to 1000 texts and a total size of 10 MB. When there is more than one bundle and <code>cores</code> is greater than 1, bundles are processed by multiple cores.</p> <p>If you have texts spread across multiple files, they can be most efficiently processed in parallel if each file contains a single text (potentially collapsed from multiple lines). If files contain multiple texts (i.e., <code>collapse_lines=False</code>), then texts need to be read in before bundling in order to ensure bundles are under the length limit.</p> Source code in <code>src\\receptiviti\\request.py</code> <pre><code>def request(\ntext: Union[str, list, pandas.DataFrame],\noutput: Union[str, None] = None,\nids: Union[str, List[Union[str, int]], None] = None,\ntext_column: Union[str, None] = None,\nid_column: Union[str, None] = None,\nfile_type: str = \"txt\",\nreturn_text=False,\napi_args: Union[dict, None] = None,\nframeworks: Union[str, List[str], None] = None,\nframework_prefix: Union[bool, None] = None,\nbundle_size=1000,\nbundle_byte_limit=75e5,\ncollapse_lines=False,\nretry_limit=50,\nclear_cache=False,\nrequest_cache=True,\ncores=cpu_count() - 2,\nin_memory: Union[bool, None] = None,\nverbose=False,\nprogress_bar=True,\noverwrite=False,\nmake_request=True,\ntext_as_paths=False,\ndotenv: Union[bool, str] = True,\ncache: Union[str, bool] = os.getenv(\"RECEPTIVITI_CACHE\", \"\"),\ncache_overwrite=False,\ncache_format=os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"\"),\nkey=os.getenv(\"RECEPTIVITI_KEY\", \"\"),\nsecret=os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\nurl=os.getenv(\"RECEPTIVITI_URL\", \"\"),\nversion=os.getenv(\"RECEPTIVITI_VERSION\", \"\"),\nendpoint=os.getenv(\"RECEPTIVITI_ENDPOINT\", \"\"),\n) -&gt; pandas.DataFrame:\n\"\"\"\n    Send texts to be scored by the API.\n    Args:\n        text (str | list | pandas.DataFrame): Text to be processed.\n        output (str): Path to a file to write results to.\n        ids (str | list): Vector of IDs for each `text`, or a column name in `text` containing IDs.\n        text_column (str): Column name in `text` containing text.\n        id_column (str): Column name in `text` containing IDs.\n        file_type (str): Extension of the file(s) to be read in from a directory (`txt` or `csv`).\n        return_text (bool): If `True`, will include a `text` column in the output with the\n            original text.\n        api_args (dict): Additional arguments to include in the request.\n        frameworks (str | list): One or more names of frameworks to return.\n        framework_prefix (bool): If `False`, will drop framework prefix from column names.\n            If one framework is selected, will default to `False`.\n        bundle_size (int): Maximum number of texts per bundle.\n        bundle_byte_limit (float): Maximum byte size of each bundle.\n        collapse_lines (bool): If `True`, will treat files as containing single texts, and\n            collapse multiple lines.\n        retry_limit (int): Number of times to retry a failed request.\n        clear_cache (bool): If `True`, will delete the `cache` before processing.\n        request_cache (bool): If `False`, will not temporarily save raw requests for reuse\n            within a day.\n        cores (int): Number of CPU cores to use when processing multiple bundles.\n        in_memory (bool | None): If `False`, will write bundles to disc, to be loaded when\n            processed. Defaults to `True` when processing in parallel.\n        verbose (bool): If `True`, will print status messages and preserve the progress bar.\n        progress_bar (bool): If `False`, will not display a progress bar.\n        overwrite (bool): If `True`, will overwrite an existing `output` file.\n        text_as_paths (bool): If `True`, will explicitly mark `text` as a list of file paths.\n            Otherwise, this will be detected.\n        dotenv (bool | str): Path to a .env file to read environment variables from. By default,\n            will for a file in the current directory or `~/Documents`.\n            Passed to `readin_env` as `path`.\n        cache (bool | str): Path to a cache directory, `True` or `\"\"` to use the default directory,\n            or `False` to not use a cache.\n        cache_overwrite (bool): If `True`, will not check the cache for previously cached texts,\n            but will store results in the cache (unlike `cache = False`).\n        cache_format (str): File format of the cache, of available Arrow formats.\n        key (str): Your API key.\n        secret (str): Your API secret.\n        url (str): The URL of the API; defaults to `https://api.receptiviti.com`.\n        version (str): Version of the API; defaults to `v1`.\n        endpoint (str): Endpoint of the API; defaults to fefe `framework`.\n    Returns:\n        Scores associated with each input text.\n    Cache:\n        By default, results for unique texts are saved in an Arrow database in the cache location\n        (`os.getenv(\"RECEPTIVITI_CACHE\")`), and are retrieved with subsequent requests. This ensures\n        that the exact same texts are not re-sent to the API. This does, however, add some\n        processing time and disc space usage.\n        If a cache location is not specified, a default directory (`receptiviti_cache`) will be\n        looked for in the system's temporary directory (`tempfile.gettempdir()`).\n        The `cache_format` arguments (or the `RECEPTIVITI_CACHE_FORMAT` environment variable) can be\n        used to adjust the format of the cache.\n        You can use the cache independently with\n        `pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))`.\n        You can set the `cache` argument to `False` to prevent the cache from being used, which\n        might make sense if you don't expect to need to reprocess texts.\n        You can also set the `clear_cache` argument to `True` to clear the cache before it is used\n        again, which may be useful if the cache has gotten big, or you know new results will be\n        returned.\n        Even if a cached result exists, it will be reprocessed if it does not have all of the\n        variables of new results, but this depends on there being at least 1 uncached result. If,\n        for instance, you add a framework to your account and want to reprocess a previously\n        processed set of texts, you would need to first clear the cache.\n        Either way, duplicated texts within the same call will only be sent once.\n        The `request_cache` argument controls a more temporary cache of each bundle request. This\n        is cleared after a day. You might want to set this to `False` if a new framework becomes\n        available on your account and you want to process a set of text you re-processed recently.\n        Another temporary cache is made when `in_memory` is `False`, which is the default when\n        processing in parallel (when there is more than 1 bundle and `cores` is over 1). This is a\n        temporary directory that contains a file for each unique bundle, which is read in as needed\n        by the parallel workers.\n    Parallelization:\n        `text`s are split into bundles based on the `bundle_size` argument. Each bundle represents\n        a single request to the API, which is why they are limited to 1000 texts and a total size\n        of 10 MB. When there is more than one bundle and `cores` is greater than 1, bundles are\n        processed by multiple cores.\n        If you have texts spread across multiple files, they can be most efficiently processed in\n        parallel if each file contains a single text (potentially collapsed from multiple lines).\n        If files contain multiple texts (i.e., `collapse_lines=False`), then texts need to be\n        read in before bundling in order to ensure bundles are under the length limit.\n    \"\"\"\nif output is not None and os.path.isfile(output) and not overwrite:\nmsg = \"`output` file already exists; use `overwrite=True` to overwrite it\"\nraise RuntimeError(msg)\nstart_time = perf_counter()\nif request_cache:\nif verbose:\nprint(f\"preparing request cache ({perf_counter() - start_time:.4f})\")\n_manage_request_cache()\n# resolve credentials and check status\nif dotenv:\nreadin_env(\".\" if isinstance(dotenv, bool) else dotenv)\nif not url:\nurl = os.getenv(\"RECEPTIVITI_URL\", \"https://api.receptiviti.com\")\nurl_parts = re.search(\"/([Vv]\\\\d)/?([^/]+)?\", url)\nif url_parts:\nfrom_url = url_parts.groups()\nif not version and from_url[0] is not None:\nversion = from_url[0]\nif not endpoint and from_url[1] is not None:\nendpoint = from_url[1]\nurl = (\"https://\" if re.match(\"http\", url, re.I) is None else \"\") + re.sub(\n\"/[Vv]\\\\d(?:/.*)?$|/+$\", \"\", url\n)\nif not key:\nkey = os.getenv(\"RECEPTIVITI_KEY\", \"\")\nif not secret:\nsecret = os.getenv(\"RECEPTIVITI_SECRET\", \"\")\nif not version:\nversion = os.getenv(\"RECEPTIVITI_VERSION\", \"v1\")\nif not endpoint:\nendpoint_default = \"framework\" if version.lower() == \"v1\" else \"taxonomies\"\nendpoint = os.getenv(\"RECEPTIVITI_ENDPOINT\", endpoint_default)\napi_status = status(url, key, secret, dotenv, verbose=False)\nif api_status.status_code != 200:\nmsg = f\"API status failed: {api_status.status_code}: {api_status.reason}\"\nraise RuntimeError(msg)\n# resolve text and ids\ndef readin(\npaths: List[str],\ntext_cols=text_column,\nid_cols=id_column,\ncollapse=collapse_lines,\n) -&gt; Union[List[str], pandas.DataFrame]:\nsel = []\nif text_cols is not None:\nsel.append(text_cols)\nif id_cols is not None:\nsel.append(id_cols)\nif os.path.splitext(paths[0])[1] == \".txt\" and not sel:\ntext = []\nfor file in paths:\nwith open(file, encoding=\"utf-8\") as texts:\nlines = [line.rstrip() for line in texts]\nif collapse:\ntext.append(\" \".join(lines))\nelse:\ntext += lines\nreturn text\nelse:\nreturn pandas.concat([pandas.read_csv(file, usecols=sel) for file in paths])\nif isinstance(text, str) and (text_as_paths or len(text) &lt; 260):\nif os.path.isfile(text):\nif verbose:\nprint(f\"reading in texts from a file ({perf_counter() - start_time:.4f})\")\ntext = readin([text])\ntext_as_paths = False\nelif os.path.isdir(text):\ntext = glob(f\"{text}/*{file_type}\")\ntext_as_paths = True\nif isinstance(text, pandas.DataFrame):\nif id_column is not None:\nif id_column in text:\nids = text[id_column].to_list()\nelse:\nmsg = f\"`id_column` ({id_column}) is not in `text`\"\nraise IndexError(msg)\nif text_column is not None:\nif text_column in text:\ntext = text[text_column].to_list()\nelse:\nmsg = f\"`text_column` ({text_column}) is not in `text`\"\nraise IndexError(msg)\nelse:\nmsg = \"`text` is a DataFrame, but no `text_column` is specified\"\nraise RuntimeError(msg)\nif isinstance(text, str):\ntext = [text]\ntext_is_path = all(\nisinstance(t, str) and (text_as_paths or len(t) &lt; 260) and os.path.isfile(t) for t in text\n)\nif text_as_paths and not text_is_path:\nmsg = \"`text` treated as a list of files, but not all of the entries exist\"\nraise RuntimeError(msg)\nif text_is_path and not collapse_lines:\ntext = readin(text)\ntext_is_path = False\nid_specified = ids is not None\nif ids is None:\nids = numpy.arange(1, len(text) + 1).tolist()\nelif len(ids) != len(text):\nmsg = \"`ids` is not the same length as `text`\"\nraise RuntimeError(msg)\noriginal_ids = set(ids)\nif len(ids) != len(original_ids):\nmsg = \"`ids` contains duplicates\"\nraise RuntimeError(msg)\n# prepare bundles\nif verbose:\nprint(f\"preparing text ({perf_counter() - start_time:.4f})\")\ndata = pandas.DataFrame({\"text\": text, \"id\": ids})\nn_original = len(data)\ndata_subset = data[\n~(data.duplicated(subset=[\"text\"]) | (data[\"text\"] == \"\") | data[\"text\"].isna())\n]\nn_texts = len(data_subset)\nif not n_texts:\nmsg = \"no valid texts to process\"\nraise RuntimeError(msg)\nbundle_size = max(1, bundle_size)\nn_bundles = math.ceil(n_texts / min(1000, bundle_size))\ngroups = data_subset.groupby(\nnumpy.sort(numpy.tile(numpy.arange(n_bundles) + 1, bundle_size))[:n_texts],\ngroup_keys=False,\n)\nbundles = []\nfor _, group in groups:\nif sys.getsizeof(group) &gt; bundle_byte_limit:\nstart = current = end = 0\nfor txt in group[\"text\"]:\nsize = os.stat(txt).st_size if text_is_path else sys.getsizeof(txt)\nif size &gt; bundle_byte_limit:\nmsg = (\n\"one of your texts is over the bundle size\"\nf\" limit ({bundle_byte_limit / 1e6} MB)\"\n)\nraise RuntimeError(msg)\nif (current + size) &gt; bundle_byte_limit:\nbundles.append(group[start:end])\nstart = end = end + 1\ncurrent = size\nelse:\nend += 1\ncurrent += size\nbundles.append(group[start:])\nelse:\nbundles.append(group)\nn_bundles = len(bundles)\nif verbose:\nprint(\nf\"prepared {n_texts} unique text{'s' if n_texts &gt; 1 else ''} in \"\nf\"{n_bundles} {'bundles' if n_bundles &gt; 1 else 'bundle'}\",\nf\"({perf_counter() - start_time:.4f})\",\n)\n# process bundles\nif isinstance(cache, str):\nif not cache:\ncache = CACHE\nif clear_cache and os.path.exists(cache):\nshutil.rmtree(cache, True)\nos.makedirs(cache, exist_ok=True)\nif not cache_format:\ncache_format = os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"parquet\")\nopts = {\n\"url\": f\"{url}/{version}/{endpoint}/bulk\".lower(),\n\"auth\": requests.auth.HTTPBasicAuth(key, secret),\n\"retries\": retry_limit,\n\"add\": {} if api_args is None else api_args,\n\"are_paths\": text_is_path,\n\"request_cache\": request_cache,\n\"cache\": \"\" if cache_overwrite or isinstance(cache, bool) and not cache else cache,\n\"cache_format\": cache_format,\n\"make_request\": make_request,\n}\nopts[\"add_hash\"] = hashlib.md5(\njson.dumps(\n{**opts[\"add\"], \"url\": opts[\"url\"], \"key\": key, \"secret\": secret},\nseparators=(\",\", \":\"),\n).encode()\n).hexdigest()\nuse_pb = (verbose and progress_bar) or progress_bar\nparallel = n_bundles &gt; 1 and cores &gt; 1\nif in_memory is None:\nin_memory = not parallel\nwith TemporaryDirectory() as scratch_cache:\nif not in_memory:\nif verbose:\nprint(f\"writing to scratch cache ({perf_counter() - start_time:.4f})\")\ndef write_to_scratch(i: int, bundle: pandas.DataFrame):\ntemp = f\"{scratch_cache}/{i}.json\"\nwith open(temp, \"wb\") as scratch:\npickle.dump(bundle, scratch)\nreturn temp\nbundles = [write_to_scratch(i, b) for i, b in enumerate(bundles)]\nif parallel:\nif verbose:\nprint(f\"requesting in parallel ({perf_counter() - start_time:.4f})\")\nwaiter: \"Queue[pandas.DataFrame]\" = Queue()\nqueue: \"Queue[tuple[int, pandas.DataFrame]]\" = Queue()\nmanager = Process(\ntarget=_queue_manager,\nargs=(queue, waiter, n_texts, n_bundles, use_pb, verbose),\n)\nmanager.start()\nnb = math.ceil(n_bundles / min(n_bundles, cores))\ncores = math.ceil(n_bundles / nb)\nprocs = [\nProcess(\ntarget=_process,\nargs=(bundles[(i * nb) : min(n_bundles, (i + 1) * nb)], opts, queue),\n)\nfor i in range(cores)\n]\nfor cl in procs:\ncl.start()\nfor cl in procs:\ncl.join()\nres = waiter.get()\nelse:\nif verbose:\nprint(f\"requesting serially ({perf_counter() - start_time:.4f})\")\nif use_pb:\npb = tqdm(total=n_texts, leave=verbose)\nres = _process(bundles, opts, pb=pb)\nif use_pb:\npb.close()\nif verbose:\nprint(f\"done requesting ({perf_counter() - start_time:.4f})\")\n# finalize\nif not res.shape[0]:\nmsg = \"no results\"\nraise RuntimeError(msg)\nif isinstance(cache, str):\n_update_cache(res, cache, cache_format, verbose, start_time, [e[0] for e in opts[\"add\"]])\nif verbose:\nprint(f\"preparing output ({perf_counter() - start_time:.4f})\")\ndata.set_index(\"id\", inplace=True)\nres.set_index(\"id\", inplace=True)\nif len(res) != n_original:\nres = res.join(data[\"text\"])\ndata_absent = data.loc[list(set(data.index).difference(res.index))]\ndata_absent = data_absent.loc[data_absent[\"text\"].isin(res[\"text\"])]\nif data.size:\nres = res.reset_index()\nres.set_index(\"text\", inplace=True)\ndata_dupes = res.loc[data_absent[\"text\"]]\ndata_dupes[\"id\"] = data_absent.index.to_list()\nres = pandas.concat([res, data_dupes])\nres.reset_index(inplace=True, drop=True)\nres.set_index(\"id\", inplace=True)\nres = res.join(data[\"text\"], how=\"outer\")\nif not return_text:\nres.drop(\"text\", axis=1, inplace=True)\nres = res.reset_index()\nif output is not None:\nif verbose:\nprint(f\"writing results to file: {output} ({perf_counter() - start_time:.4f})\")\nres.to_csv(output, index=False)\ndrops = [\"custom\", \"bin\"]\nif not id_specified:\ndrops.append(\"id\")\nres.drop(\nlist({*drops}.intersection(res.columns)),\naxis=\"columns\",\ninplace=True,\n)\nif frameworks is not None:\nif verbose:\nprint(f\"selecting frameworks ({perf_counter() - start_time:.4f})\")\nif isinstance(frameworks, str):\nframeworks = [frameworks]\nif len(frameworks) == 1 and framework_prefix is None:\nframework_prefix = False\nselect = []\nif id_specified:\nselect.append(\"id\")\nif return_text:\nselect.append(\"text\")\nselect.append(\"text_hash\")\nres = res.filter(regex=f\"^(?:{'|'.join(select + frameworks)})(?:$|\\\\.)\")\nif isinstance(framework_prefix, bool) and not framework_prefix:\nprefix_pattern = re.compile(\"^[^.]+\\\\.\")\nres.columns = pandas.Index([prefix_pattern.sub(\"\", col) for col in res.columns])\nif verbose:\nprint(f\"done ({perf_counter() - start_time:.4f})\")\nreturn res\n</code></pre>"},{"location":"functions/status/","title":"Status","text":"<p>Check the status of the API.</p>"},{"location":"functions/status/#receptiviti.status.status","title":"<code>status(url=os.getenv('RECEPTIVITI_URL', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), dotenv=False, verbose=True)</code>","text":"<p>Check the API's status.</p> <p>Ping the Receptiviti API to see if it's available, and if your credentials are valid.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the API.</p> <code>os.getenv('RECEPTIVITI_URL', '')</code> <code>key</code> <code>str</code> <p>Your API key.</p> <code>os.getenv('RECEPTIVITI_KEY', '')</code> <code>secret</code> <code>str</code> <p>Your API secret.</p> <code>os.getenv('RECEPTIVITI_SECRET', '')</code> <code>dotenv</code> <code>bool | str</code> <p>Path to a .env file to read environment variables from, or <code>True</code> to look for a file in the current directory.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If <code>False</code>, will not print status messages.</p> <code>True</code> <p>Returns:</p> Type Description <code>Response</code> <p>Response from the API server.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; receptiviti.status()\n</code></pre> Source code in <code>src\\receptiviti\\status.py</code> <pre><code>def status(\nurl: str = os.getenv(\"RECEPTIVITI_URL\", \"\"),\nkey: str = os.getenv(\"RECEPTIVITI_KEY\", \"\"),\nsecret: str = os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\ndotenv: Union[bool, str] = False,\nverbose=True,\n) -&gt; requests.Response:\n\"\"\"\n    Check the API's status.\n    Ping the Receptiviti API to see if it's available, and if your credentials are valid.\n    Args:\n      url (str): The URL of the API.\n      key (str): Your API key.\n      secret (str): Your API secret.\n      dotenv (bool | str): Path to a .env file to read environment variables from, or `True`\n        to look for a file in the current directory.\n      verbose (bool): If `False`, will not print status messages.\n    Returns:\n      Response from the API server.\n    Examples:\n        &gt;&gt;&gt; receptiviti.status()\n    \"\"\"\nif dotenv is not None and dotenv:\nreadin_env(\".\" if isinstance(dotenv, bool) else dotenv)\nif not url:\nurl = os.getenv(\"RECEPTIVITI_URL\", \"https://api.receptiviti.com\")\nif not key:\nkey = os.getenv(\"RECEPTIVITI_KEY\", \"\")\nif not secret:\nsecret = os.getenv(\"RECEPTIVITI_SECRET\", \"\")\nurl = (\"https://\" if re.match(\"http\", url, re.I) is None else \"\") + re.sub(\n\"/[Vv]\\\\d(?:/.*)?$|/+$\", \"\", url\n)\nif re.match(\"https?://[^.]+[.:][^.]\", url, re.I) is None:\nraise TypeError(\"`url` does not appear to be valid: \" + url)\nres = requests.get(url.lower() + \"/v1/ping\", auth=(key, secret), timeout=9999)\ncontent = res.json() if res.text[:1] == \"{\" else {\"message\": res.text}\nif verbose:\nprint(\"Status: \" + (\"OK\" if res.status_code == 200 else \"ERROR\"))\nprint(\n\"Message: \"\n+ (\nstr(res.status_code)\n+ (\" (\" + str(content[\"code\"]) + \")\" if \"code\" in content else \"\")\n+ \": \"\n+ content[\"pong\" if \"pong\" in content else \"message\"]\n)\n)\nreturn res\n</code></pre>"}]}