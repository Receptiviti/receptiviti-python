{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A Python package to process text with the Receptiviti API.</p> <p>An R package is also available at Receptiviti/receptiviti-r.</p>"},{"location":"#installation","title":"Installation","text":"<p>If needed, download Python from python.org, then install the package with pip:</p> <p>Release (version 0.1.2)</p> <pre><code>pip install receptiviti\n</code></pre> <p>Development</p> <pre><code>pip install git+https://github.com/receptiviti/receptiviti-python.git\n</code></pre> <p>And load the package in a python console:</p> <pre><code>import receptiviti\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<pre><code># score a single text\nsingle = receptiviti.request(\"a text to score\")\n\n# score multiple texts, and write results to a file\nmulti = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n\n# score texts in separate files\n## defaults to look for .txt files\nfile_results = receptiviti.request(directory = \"./path/to/txt_folder\")\n\n## could be .csv\nfile_results = receptiviti.request(\n  directory = \"./path/to/csv_folder\",\n  text_column = \"text\", file_type = \"csv\"\n)\n\n# score texts in a single file\nresults = receptiviti.request(\"./path/to/file.csv\", text_column = \"text\")\n</code></pre>"},{"location":"#api-access","title":"API Access","text":"<p>To access the API, you will need to load your key and secret, as found on your dashboard.</p> <p>You can enter these as arguments in each function call, but by default they will be looked for in these environment variables:</p> <pre><code>RECEPTIVITI_KEY=\"32lettersandnumbers\"\nRECEPTIVITI_SECRET=\"56LettersAndNumbers\"\n</code></pre> <p>You can store these in a <code>.env</code> file (in the current directory or <code>~/Documents</code>) permanently, or set them temporarily:</p> <pre><code>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</code></pre>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#receptiviti-013","title":"receptiviti 0.1.3","text":""},{"location":"CHANGELOG/#additions","title":"Additions","text":"<ul> <li>Adds support for V2 of the API.</li> <li>Adds custom norming context creation functionality.</li> </ul>"},{"location":"CHANGELOG/#improvements","title":"Improvements","text":"<ul> <li>Improves cache performance.</li> <li>Validates <code>version</code> and <code>endpoint</code>.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Avoids overwriting existing cache results within overlapping bins on update.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-012","title":"receptiviti 0.1.2","text":""},{"location":"CHANGELOG/#improvements_1","title":"Improvements","text":"<ul> <li>Changes default number of cores to 1, to avoid unexpected behavior when running from a script.</li> <li>Improves environment file resolution.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>Corrects order of output when reading from a file and <code>ids</code> are not specified.</li> <li>Fixes detection of some file encodings.</li> <li>Avoids issues when <code>receptiviti.request</code> is called from a script and is processing in parallel.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-011","title":"receptiviti 0.1.1","text":""},{"location":"CHANGELOG/#improvements_2","title":"Improvements","text":"<ul> <li>Adds <code>encoding</code> argument; improves handling of non-UTF-8 files.</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>Fixes reading in files when <code>collapse_line</code> is <code>True</code>.</li> </ul>"},{"location":"CHANGELOG/#receptiviti-010","title":"receptiviti 0.1.0","text":"<p>First release.</p>"},{"location":"articles/quick_start/","title":"Get Started","text":"In\u00a0[2]: Copied! <pre>import receptiviti\n</pre> import receptiviti In\u00a0[3]: Copied! <pre>receptiviti.status()\n</pre> receptiviti.status() <pre>Status: OK\nMessage: 200: Hello there, World!\n</pre> Out[3]: <pre>&lt;Response [200]&gt;</pre> <p>If your credentials are not recognized, you'll get a response like this:</p> In\u00a0[4]: Copied! <pre>receptiviti.status(key=123, secret=123)\n</pre> receptiviti.status(key=123, secret=123) <pre>Status: ERROR\nMessage: 401 (1411): Unrecognized API key pair. This call will not count towards your plan.\n</pre> Out[4]: <pre>&lt;Response [401]&gt;</pre> In\u00a0[5]: Copied! <pre>results = receptiviti.request(\"texts to score\")\n</pre> results = receptiviti.request(\"texts to score\") <p>Or a character vector:</p> In\u00a0[6]: Copied! <pre>results = receptiviti.request([\"text one\", \"text two\"])\n</pre> results = receptiviti.request([\"text one\", \"text two\"]) <p>Or from a <code>DataFrame</code>:</p> In\u00a0[7]: Copied! <pre>import pandas\ndata = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})\n\n# directly\nresults = receptiviti.request(data[\"text\"])\n\n# by column name\nresults = receptiviti.request(data, text_column=\"text\")\n</pre> import pandas data = pandas.DataFrame({\"text\": [\"text a\", \"text b\"]})  # directly results = receptiviti.request(data[\"text\"])  # by column name results = receptiviti.request(data, text_column=\"text\") In\u00a0[8]: Copied! <pre># single\nresults = receptiviti.request(\"files/file.txt\")\n\n# multiple\nresults = receptiviti.request(\n  files = [\"files/file1.txt\", \"files/file2.txt\"]\n)\n</pre> # single results = receptiviti.request(\"files/file.txt\")  # multiple results = receptiviti.request(   files = [\"files/file1.txt\", \"files/file2.txt\"] ) <p>Or to a comma delimited file with a column containing text. Here, the <code>text_column</code> argument specifies which column contains text:</p> In\u00a0[9]: Copied! <pre># single\nresults = receptiviti.request(\"files/file.csv\", text_column=\"text\")\n\n# multiple\nresults = receptiviti.request(\n  files = [\"files/file1.csv\", \"files/file2.csv\"],\n  text_column=\"text\"\n)\n</pre> # single results = receptiviti.request(\"files/file.csv\", text_column=\"text\")  # multiple results = receptiviti.request(   files = [\"files/file1.csv\", \"files/file2.csv\"],   text_column=\"text\" ) <p>Or you can point to a directory containing text files:</p> In\u00a0[10]: Copied! <pre>results = receptiviti.request(directory = \"files\")\n</pre> results = receptiviti.request(directory = \"files\") <p>By default <code>.txt</code> files will be looked for, but you can specify <code>.csv</code> files with the <code>file_type</code> argument:</p> In\u00a0[11]: Copied! <pre>results = receptiviti.request(\n  directory = \"files\",\n  text_column=\"text\", file_type=\"csv\"\n)\n</pre> results = receptiviti.request(   directory = \"files\",   text_column=\"text\", file_type=\"csv\" ) In\u00a0[12]: Copied! <pre>results = receptiviti.request(\"texts to score\")\nresults.iloc[:, :3]\n</pre> results = receptiviti.request(\"texts to score\") results.iloc[:, :3] Out[12]: text_hash summary.word_count summary.words_per_sentence 0 acab8277267d0efee0828f94e0919ddf 3 3 <p>Here, the first column (<code>text_hash</code>) is the MD5 hash of the text, which identifies unique texts, and is stored in the main cache.</p> <p>The entered text can also be included with the <code>return_text</code> argument:</p> In\u00a0[13]: Copied! <pre>results = receptiviti.request(\"texts to score\", return_text=True)\nresults[[\"text_hash\", \"text\"]]\n</pre> results = receptiviti.request(\"texts to score\", return_text=True) results[[\"text_hash\", \"text\"]] Out[13]: text_hash text 0 acab8277267d0efee0828f94e0919ddf texts to score <p>You can also select frameworks before they are all returned:</p> In\u00a0[14]: Copied! <pre>results = receptiviti.request(\"texts to score\", frameworks=\"liwc\")\nresults.iloc[:, :5]\n</pre> results = receptiviti.request(\"texts to score\", frameworks=\"liwc\") results.iloc[:, :5] Out[14]: text_hash analytical_thinking clout authentic emotional_tone 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 0.257742 <p>By default, a single framework will have column names without the framework name, but you can retain these with <code>framework_prefix=True</code>:</p> In\u00a0[15]: Copied! <pre>results = receptiviti.request(\n  \"texts to score\",\n  frameworks=\"liwc\", framework_prefix=True\n)\nresults.iloc[:, :4]\n</pre> results = receptiviti.request(   \"texts to score\",   frameworks=\"liwc\", framework_prefix=True ) results.iloc[:, :4] Out[15]: text_hash liwc.analytical_thinking liwc.clout liwc.authentic 0 acab8277267d0efee0828f94e0919ddf 0.99 0.5 0.01 In\u00a0[16]: Copied! <pre>data = pandas.DataFrame({\n  \"id\": [1, 2, 3, 4],\n  \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"]\n})\nresults = receptiviti.request(data[\"text\"])\n\n# combine data and results\ndata.join(results).iloc[:, :5]\n</pre> data = pandas.DataFrame({   \"id\": [1, 2, 3, 4],   \"text\": [\"text a\", float(\"nan\"), \"\", \"text a\"] }) results = receptiviti.request(data[\"text\"])  # combine data and results data.join(results).iloc[:, :5] Out[16]: id text text_hash summary.word_count summary.words_per_sentence 0 1 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 1 2 NaN NaN NaN NaN 2 3 NaN NaN NaN 3 4 text a 42ff59040f004970040f90a19aa6b3fa 2.0 2.0 <p>You can also provide a vector of unique IDs to be returned with results so they can be merged with other data:</p> In\u00a0[17]: Copied! <pre>results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"])\nresults.iloc[:, :4]\n</pre> results = receptiviti.request([\"text a\", \"text b\"], ids=[\"a\", \"b\"]) results.iloc[:, :4] Out[17]: id text_hash summary.word_count summary.words_per_sentence 0 a 42ff59040f004970040f90a19aa6b3fa 2 2 1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 In\u00a0[18]: Copied! <pre># merge with a new dataset\ndata = pandas.DataFrame({\n  \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],\n  \"type\": [\"a\", \"b\", \"a\", \"b\"]\n})\ndata.join(results.set_index(\"id\"), \"type\").iloc[:, :5]\n</pre> # merge with a new dataset data = pandas.DataFrame({   \"id\": [\"a1\", \"b1\", \"a2\", \"b2\"],   \"type\": [\"a\", \"b\", \"a\", \"b\"] }) data.join(results.set_index(\"id\"), \"type\").iloc[:, :5] Out[18]: id type text_hash summary.word_count summary.words_per_sentence 0 a1 a 42ff59040f004970040f90a19aa6b3fa 2 2 1 b1 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 2 a2 a 42ff59040f004970040f90a19aa6b3fa 2 2 3 b2 b 4db2bfd2c8140dffac0060c9fb1c6d6f 2 2 In\u00a0[19]: Copied! <pre>receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True)\nresults = pandas.read_csv(\"~/Documents/results.csv\")\nresults.iloc[:, :4]\n</pre> receptiviti.request(\"texts to score\", \"~/Documents/results.csv\", overwrite=True) results = pandas.read_csv(\"~/Documents/results.csv\") results.iloc[:, :4] Out[19]: id text_hash summary.word_count summary.words_per_sentence 0 1 acab8277267d0efee0828f94e0919ddf 3 3"},{"location":"articles/quick_start/#install-and-load","title":"Install and Load\u00b6","text":"<p>First, download and install Python from python.org.</p> <p>Then, install the package:</p> <pre>pip install git+https://github.com/receptiviti/receptiviti-python.git\n</pre> <p>Each time you start a Python session, load the package:</p>"},{"location":"articles/quick_start/#set-up-api-credentials","title":"Set Up API Credentials\u00b6","text":"<p>You can find your API key and secret on your dashboard.</p> <p>You can set these credentials up in Python permanently or temporarily:</p>"},{"location":"articles/quick_start/#permanent","title":"Permanent\u00b6","text":"<p>Open or create a <code>~/.env</code> file, Then add these environment variables with your key and secret:</p> <pre>RECEPTIVITI_KEY=\"\"\nRECEPTIVITI_SECRET=\"\"\n</pre> <p>These can be read in with the <code>receptiviti.readin_env()</code> function, which is automatically called if credentials are not otherwise provided (and the <code>dotenv</code> argument is <code>True</code>).</p>"},{"location":"articles/quick_start/#temporary","title":"Temporary\u00b6","text":"<p>Add your key and secret, and run at the start of each session:</p> <pre>import os\nos.environ[\"RECEPTIVITI_KEY\"]=\"32lettersandnumbers\"\nos.environ[\"RECEPTIVITI_SECRET\"]=\"56LettersAndNumbers\"\n</pre>"},{"location":"articles/quick_start/#confirm-credentials","title":"Confirm Credentials\u00b6","text":"<p>Check that the API is reachable, and your credentials are recognized:</p>"},{"location":"articles/quick_start/#enter-your-text","title":"Enter Your Text\u00b6","text":""},{"location":"articles/quick_start/#loaded-text","title":"Loaded Text\u00b6","text":"<p>If your texts are already in Python, you can enter them directly.</p> <p>These can be in a single character:</p>"},{"location":"articles/quick_start/#text-in-files","title":"Text in files\u00b6","text":"<p>You can enter paths to files containing separate texts in each line:</p>"},{"location":"articles/quick_start/#use-results","title":"Use Results\u00b6","text":""},{"location":"articles/quick_start/#returned-results","title":"Returned Results\u00b6","text":"<p>Results are returned as a <code>DataFrame</code>, with a row for each text, and columns for each framework variable:</p>"},{"location":"articles/quick_start/#aligning-results","title":"Aligning Results\u00b6","text":"<p>Results are returned in a way that aligns with the text you enter originally, including any duplicates or invalid entries.</p> <p>This means you can add the results object to original data:</p>"},{"location":"articles/quick_start/#saved-results","title":"Saved Results\u00b6","text":"<p>Results can also be saved to a <code>.csv</code> file:</p>"},{"location":"articles/quick_start/#preserving-results","title":"Preserving Results\u00b6","text":"<p>The <code>receptiviti.request</code> function tries to avoid sending texts to the API as much as possible:</p> <ul> <li>As part of the preparation process, it excludes duplicates and invalid texts.</li> <li>If enabled, it checks the primary cache to see if any texts have already been scored.<ul> <li>The primary cache is an Arrow database located by the <code>cache</code> augment.</li> <li>Its format is determined by <code>cache_format</code>.</li> <li>You can skip checking it initially while still writing results to it with <code>cache_overwrite=True</code>.</li> <li>It can be cleared with <code>clear_cache=True</code>.</li> </ul> </li> <li>It will check for any responses to previous, identical requests.<ul> <li>Responses are stored in the <code>receptiviti_request_cache</code> directory of your system's temporary directory (<code>tempfile.gettempdir()</code>).</li> <li>You can avoid using this cache with <code>request_cache=False</code>.</li> <li>This cache is cleared after a day.</li> </ul> </li> </ul> <p>If you want to make sure no texts are sent to the API, you can use <code>make_request=False</code>. This will use the primary and request cache, but will fail if any texts are not found there.</p> <p>If a call fails before results can be written to the cache or returned, all received responses will still be in the request cache, but those will be deleted after a day.</p>"},{"location":"articles/quick_start/#handling-big-data","title":"Handling Big Data\u00b6","text":"<p>The <code>receptiviti.request</code> function will handle splitting texts into bundles, so the limit on how many texts you can process at once will come down to your system's amount of random access memory (RAM). Several thousands of texts should be fine, but getting into millions of texts, you may not be able to have all of the results loaded at once. To get around this, you can fully process subsets of your texts.</p> <p>A benefit of processing more texts at once is that requests can be parallelized, but this is more RAM intensive, and the primary cache is updated less frequently (as it is updated only at the end of a complete run).</p> <p>You could also parallelize your own batches, but be sure to set <code>cores</code> to <code>1</code> (to disable the function's parallelization) and do not enable the primary cache (to avoid attempting to read from the cache while it is being written to by another instance).</p> <p>Not using the primary cache is also more efficient, but you may want to ensure you are not sending duplicate texts between calls. The function handles duplicate texts within calls (only ever sending unique texts), but depends on the cache to avoid sending duplicates between calls.</p>"},{"location":"functions/norming/","title":"Norming","text":"<p>Interact with the norming endpoint.</p>"},{"location":"functions/norming/#receptiviti.norming.norming","title":"<code>norming(name=None, text=None, options=None, dotenv=True, key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), url=os.getenv('RECEPTIVITI_URL', ''), verbose=True, **kwargs)</code>","text":"<p>View or Establish Custom Norming Contexts.</p> <p>Custom norming contexts can be used to process later texts by specifying the <code>custom_context</code> API argument in the <code>receptiviti.request</code> function (e.g., <code>receptiviti.request(\"text to score\", version = \"v2\", options = {\"custom_context\": \"norm_name\"})</code>, where <code>norm_name</code> is the name you set here).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of a new norming context, to be established from the provided 'text'. Not providing a name will list the previously created contexts.</p> <code>None</code> <code>text</code> <code>str</code> <p>Text to be processed and used as the custom norming context. Not providing text will return the status of the named norming context.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Options to set for the norming context (e.g., <code>{\"word_count_filter\": 350, \"punctuation_filter\": .25}</code>).</p> <code>None</code> <code>dotenv</code> <code>bool | str</code> <p>Path to a .env file to read environment variables from. By default, will for a file in the current directory or <code>~/Documents</code>. Passed to <code>readin_env</code> as <code>path</code>.</p> <code>True</code> <code>key</code> <code>str</code> <p>Your API key.</p> <code>getenv('RECEPTIVITI_KEY', '')</code> <code>secret</code> <code>str</code> <p>Your API secret.</p> <code>getenv('RECEPTIVITI_SECRET', '')</code> <code>url</code> <code>str</code> <p>The URL of the API; defaults to <code>https://api.receptiviti.com</code>.</p> <code>getenv('RECEPTIVITI_URL', '')</code> <code>verbose</code> <code>bool</code> <p>If <code>False</code>, will not show status messages.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments to specify how tests are read in and processed; see receptiviti.request.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[DataFrame, Series, dict[str, Union[Series, DataFrame, None]]]</code> <p>Either a <code>pandas.DataFrame</code> containing all existing custom context statuses (if no <code>name</code> is specified), a <code>pandas.Series</code> containing the the status of <code>name</code> (if <code>text</code> is not specified), or a dictionary:</p> <ul> <li><code>initial_status</code>: Initial status of the context.</li> <li><code>first_pass</code>: Response after texts are sent the first time, or <code>None</code> if the initial status is <code>pass_two</code>.</li> <li><code>second_pass</code>: Response after texts are sent the second time.</li> </ul> <p>Examples:</p> <p>List current custom contexts:</p> <pre><code>&gt;&gt;&gt; receptiviti.norming()\n</code></pre> <p>Create or get the status of a single context:</p> <pre><code>&gt;&gt;&gt; receptiviti.norming(\"new_context\")\n</code></pre> <p>Send tests to establish the context, just like the receptiviti.request function.</p> <p>Such as directly:</p> <pre><code>&gt;&gt;&gt; receptiviti.norming(\"new_context\", [\"text to send\", \"another text\"])\n</code></pre> <p>Or from a file:</p> <pre><code>&gt;&gt;&gt; receptiviti.norming(\"new_context\", \"./path/to/file.csv\", text_column = \"text\")\n</code></pre> Source code in <code>src\\receptiviti\\norming.py</code> <pre><code>def norming(\n    name: Union[str, None] = None,\n    text: Union[str, List[str], pandas.DataFrame, None] = None,\n    options: Union[dict, None] = None,\n    dotenv: Union[bool, str] = True,\n    key=os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret=os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    url=os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    verbose=True,\n    **kwargs,\n) -&gt; Union[pandas.DataFrame, pandas.Series, \"dict[str, Union[pandas.Series, pandas.DataFrame, None]]\"]:\n    \"\"\"\n    View or Establish Custom Norming Contexts.\n\n    Custom norming contexts can be used to process later texts by specifying the\n    `custom_context` API argument in the `receptiviti.request` function (e.g.,\n    `receptiviti.request(\"text to score\", version = \"v2\", options = {\"custom_context\": \"norm_name\"})`,\n    where `norm_name` is the name you set here).\n\n    Args:\n        name (str): Name of a new norming context, to be established from the provided 'text'.\n            Not providing a name will list the previously created contexts.\n        text (str): Text to be processed and used as the custom norming context.\n            Not providing text will return the status of the named norming context.\n        options (dict): Options to set for the norming context (e.g.,\n            `{\"word_count_filter\": 350, \"punctuation_filter\": .25}`).\n        dotenv (bool | str): Path to a .env file to read environment variables from. By default,\n            will for a file in the current directory or `~/Documents`.\n            Passed to `readin_env` as `path`.\n        key (str): Your API key.\n        secret (str): Your API secret.\n        url (str): The URL of the API; defaults to `https://api.receptiviti.com`.\n        verbose (bool): If `False`, will not show status messages.\n        **kwargs (Any): Additional arguments to specify how tests are read in and processed;\n            see [receptiviti.request][receptiviti.request].\n\n    Returns:\n        Either a `pandas.DataFrame` containing all existing custom context statuses\n            (if no `name` is specified), a `pandas.Series` containing the the status of\n            `name` (if `text` is not specified), or a dictionary:\n\n            - `initial_status`: Initial status of the context.\n            - `first_pass`: Response after texts are sent the first time, or\n            `None` if the initial status is `pass_two`.\n            - `second_pass`: Response after texts are sent the second time.\n\n    Examples:\n        List current custom contexts:\n        &gt;&gt;&gt; receptiviti.norming()\n\n        Create or get the status of a single context:\n        &gt;&gt;&gt; receptiviti.norming(\"new_context\")\n\n        Send tests to establish the context, just like\n        the [receptiviti.request][receptiviti.request] function.\n\n        Such as directly:\n        &gt;&gt;&gt; receptiviti.norming(\"new_context\", [\"text to send\", \"another text\"])\n\n        Or from a file:\n        &gt;&gt;&gt; receptiviti.norming(\"new_context\", \"./path/to/file.csv\", text_column = \"text\")\n    \"\"\"\n    _, url, key, secret = _resolve_request_def(url, key, secret, dotenv)\n    url += \"/v2/norming/\"\n    if name and re.search(\"[^a-z0-9_.-]\", name):\n        msg = \"`name` can only include lowercase letters, numbers, hyphens, underscores, or periods\"\n        raise RuntimeError(msg)\n    auth = requests.auth.HTTPBasicAuth(key, secret)\n\n    # list current context\n    if verbose:\n        print(\"requesting list of existing custom norming contests\")\n    req = requests.get(url, auth=auth, timeout=9999)\n    if req.status_code != 200:\n        msg = f\"failed to make norming list request: {req.status_code} {req.reason}\"\n        raise RuntimeError(msg)\n    norms = pandas.json_normalize(req.json())\n    if not name:\n        if len(norms):\n            if verbose:\n                print(\"custom norming context(s) found: \" + \", \".join(norms[\"name\"]))\n        elif verbose:\n            print(\"no custom norming contexts found\")\n        return norms\n\n    if len(norms) and name in norms[\"name\"].values:\n        status = norms[norms[\"name\"] == name].iloc[0]\n        if options:\n            warnings.warn(UserWarning(f\"context {name} already exists, so options do not apply\"), stacklevel=2)\n    else:\n        if verbose:\n            print(f\"requesting creation of context {name}\")\n        req = requests.post(url, json.dumps({\"name\": name, **(options if options else {})}), auth=auth, timeout=9999)\n        if req.status_code != 200:\n            msg = f\"failed to make norming creation request: {req.json().get('error', 'reason unknown')}\"\n            raise RuntimeError(msg)\n        status = pandas.json_normalize(req.json()).iloc[0]\n        if options:\n            for param, value in options.items():\n                if param not in status:\n                    warnings.warn(UserWarning(f\"option {param} was not set\"), stacklevel=2)\n                elif value != status[param]:\n                    warnings.warn(UserWarning(f\"set option {param} does not match the requested value\"), stacklevel=2)\n    if verbose:\n        print(f\"status of {name}:\")\n        print(status)\n    if not text:\n        return status\n    status_step = status[\"status\"]\n    if status_step == \"completed\":\n        warnings.warn(UserWarning(\"status is `completes`, so cannot send text\"), stacklevel=2)\n        return {\"initial_status\": status, \"first_pass\": None, \"second_pass\": None}\n    if status_step == \"pass_two\":\n        first_pass = None\n    else:\n        if verbose:\n            print(f\"sending first-pass sample for {name}\")\n        _, first_pass, _ = _manage_request(\n            text=text,\n            **kwargs,\n            dotenv=dotenv,\n            key=key,\n            secret=secret,\n            url=f\"{url}{name}/one\",\n            to_norming=True,\n        )\n    second_pass = None\n    if first_pass is not None and (first_pass[\"analyzed\"] == 0).all():\n        warnings.warn(\n            UserWarning(\"no texts were successfully analyzed in the first pass, so second pass was skipped\"),\n            stacklevel=2,\n        )\n    else:\n        if verbose:\n            print(f\"sending second-pass samples for {name}\")\n        _, second_pass, _ = _manage_request(\n            text=text,\n            **kwargs,\n            dotenv=dotenv,\n            key=key,\n            secret=secret,\n            url=f\"{url}{name}/two\",\n            to_norming=True,\n        )\n    if second_pass is None or (second_pass[\"analyzed\"] == 0).all():\n        warnings.warn(UserWarning(\"no texts were successfully analyzed in the second pass\"), stacklevel=2)\n    return {\"initial_stats\": status, \"first_pass\": first_pass, \"second_pass\": second_pass}\n</code></pre>"},{"location":"functions/readin_env/","title":"Readin env","text":"<p>Read in a environment variables.</p>"},{"location":"functions/readin_env/#receptiviti.readin_env.readin_env","title":"<code>readin_env(path='.', name='.env', overwrite=False)</code>","text":"<p>Set environment variables from a .env file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to a .env file, or to a directory containing such a file. By default, this will fall back on <code>~</code> then <code>~/Documents</code>.</p> <code>'.'</code> <code>name</code> <code>str</code> <p>Name of the file, when <code>path</code> points to a directory. By default, this will fall back on <code>.Renviron</code>.</p> <code>'.env'</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, overwrites existing environment variables with the same name as those in the .env file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>If a file is found, it will add contents to <code>os.environ</code>.</p> Source code in <code>src\\receptiviti\\readin_env.py</code> <pre><code>def readin_env(path=\".\", name=\".env\", overwrite=False) -&gt; None:\n    \"\"\"\n    Set environment variables from a .env file.\n\n    Args:\n      path (str): Path to a .env file, or to a directory containing such a file.\n        By default, this will fall back on `~` then `~/Documents`.\n      name (str): Name of the file, when `path` points to a directory.\n        By default, this will fall back on `.Renviron`.\n      overwrite (bool): If `True`, overwrites existing environment variables with\n        the same name as those in the .env file.\n\n    Returns:\n      If a file is found, it will add contents to `os.environ`.\n    \"\"\"\n    path = os.path.expanduser(path)\n    envpath = path if os.path.isfile(path) else path + \"/\" + name\n    if os.path.isfile(envpath):\n        ql = re.compile(\"^['\\\"]|['\\\"\\\\s]+$\")\n        with open(envpath, encoding=\"utf-8\") as file:\n            for line in file:\n                entry = line.split(\"=\", 1)\n                if len(entry) == 2 and (overwrite or os.getenv(entry[0]) is None):\n                    os.environ[entry[0]] = ql.sub(\"\", entry[1])\n    elif name != \".Renviron\":\n        readin_env(path, \".Renviron\", overwrite)\n    elif os.path.isfile(os.path.expanduser(\"~/\") + name):\n        readin_env(\"~\", name, overwrite)\n    elif os.path.isfile(os.path.expanduser(\"~/Documents/\") + name):\n        readin_env(\"~/Documents\", name, overwrite)\n</code></pre>"},{"location":"functions/request/","title":"Request","text":"<p>Make requests to the API.</p>"},{"location":"functions/request/#receptiviti.request.request","title":"<code>request(text=None, output=None, ids=None, text_column=None, id_column=None, files=None, directory=None, file_type='txt', encoding=None, return_text=False, api_args=None, frameworks=None, framework_prefix=None, bundle_size=1000, bundle_byte_limit=7500000.0, collapse_lines=False, retry_limit=50, clear_cache=False, request_cache=True, cores=1, in_memory=None, verbose=False, progress_bar=os.getenv('RECEPTIVITI_PB', 'True'), overwrite=False, make_request=True, text_as_paths=False, dotenv=True, cache=os.getenv('RECEPTIVITI_CACHE', ''), cache_overwrite=False, cache_format=os.getenv('RECEPTIVITI_CACHE_FORMAT', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), url=os.getenv('RECEPTIVITI_URL', ''), version=os.getenv('RECEPTIVITI_VERSION', ''), endpoint=os.getenv('RECEPTIVITI_ENDPOINT', ''))</code>","text":"<p>Send texts to be scored by the API.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list[str] | DataFrame</code> <p>Text to be processed, as a string or vector of strings containing the text itself, or the path to a file from which to read in text. If a DataFrame, <code>text_column</code> is used to extract such a vector. A string may also represent a directory in which to search for files. To best ensure paths are not treated as texts, either set <code>text_as_path</code> to <code>True</code>, or use <code>directory</code> to enter a directory path, or <code>files</code> to enter a vector of file paths.</p> <code>None</code> <code>output</code> <code>str</code> <p>Path to a file to write results to.</p> <code>None</code> <code>ids</code> <code>str | list[str | int]</code> <p>Vector of IDs for each <code>text</code>, or a column name in <code>text</code> containing IDs.</p> <code>None</code> <code>text_column</code> <code>str</code> <p>Column name in <code>text</code> containing text.</p> <code>None</code> <code>id_column</code> <code>str</code> <p>Column name in <code>text</code> containing IDs.</p> <code>None</code> <code>files</code> <code>list[str]</code> <p>Vector of file paths, as alternate entry to <code>text</code>.</p> <code>None</code> <code>directory</code> <code>str</code> <p>A directory path to search for files in, as alternate entry to <code>text</code>.</p> <code>None</code> <code>file_type</code> <code>str</code> <p>Extension of the file(s) to be read in from a directory (<code>txt</code> or <code>csv</code>).</p> <code>'txt'</code> <code>encoding</code> <code>str | None</code> <p>Encoding of file(s) to be read in; one of the standard encodings. If this is <code>None</code> (default), encoding will be predicted for each file, but this can potentially fail, resulting in mis-encoded characters. For best (and fastest) results, specify encoding.</p> <code>None</code> <code>return_text</code> <code>bool</code> <p>If <code>True</code>, will include a <code>text</code> column in the output with the original text.</p> <code>False</code> <code>api_args</code> <code>dict</code> <p>Additional arguments to include in the request.</p> <code>None</code> <code>frameworks</code> <code>str | list</code> <p>One or more names of frameworks to return.</p> <code>None</code> <code>framework_prefix</code> <code>bool</code> <p>If <code>False</code>, will drop framework prefix from column names. If one framework is selected, will default to <code>False</code>.</p> <code>None</code> <code>bundle_size</code> <code>int</code> <p>Maximum number of texts per bundle.</p> <code>1000</code> <code>bundle_byte_limit</code> <code>float</code> <p>Maximum byte size of each bundle.</p> <code>7500000.0</code> <code>collapse_lines</code> <code>bool</code> <p>If <code>True</code>, will treat files as containing single texts, and collapse multiple lines.</p> <code>False</code> <code>retry_limit</code> <code>int</code> <p>Number of times to retry a failed request.</p> <code>50</code> <code>clear_cache</code> <code>bool</code> <p>If <code>True</code>, will delete the <code>cache</code> before processing.</p> <code>False</code> <code>request_cache</code> <code>bool</code> <p>If <code>False</code>, will not temporarily save raw requests for reuse within a day.</p> <code>True</code> <code>cores</code> <code>int</code> <p>Number of CPU cores to use when processing multiple bundles.</p> <code>1</code> <code>in_memory</code> <code>bool | None</code> <p>If <code>False</code>, will write bundles to disc, to be loaded when processed. Defaults to <code>True</code> when processing in parallel.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, will print status messages and preserve the progress bar.</p> <code>False</code> <code>progress_bar</code> <code>str | bool</code> <p>If <code>False</code>, will not display a progress bar.</p> <code>getenv('RECEPTIVITI_PB', 'True')</code> <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, will overwrite an existing <code>output</code> file.</p> <code>False</code> <code>text_as_paths</code> <code>bool</code> <p>If <code>True</code>, will explicitly mark <code>text</code> as a list of file paths. Otherwise, this will be detected.</p> <code>False</code> <code>dotenv</code> <code>bool | str</code> <p>Path to a .env file to read environment variables from. By default, will for a file in the current directory or <code>~/Documents</code>. Passed to <code>readin_env</code> as <code>path</code>.</p> <code>True</code> <code>cache</code> <code>bool | str</code> <p>Path to a cache directory, or <code>True</code> to use the default directory.</p> <code>getenv('RECEPTIVITI_CACHE', '')</code> <code>cache_overwrite</code> <code>bool</code> <p>If <code>True</code>, will not check the cache for previously cached texts, but will store results in the cache (unlike <code>cache = False</code>).</p> <code>False</code> <code>cache_format</code> <code>str</code> <p>File format of the cache, of available Arrow formats.</p> <code>getenv('RECEPTIVITI_CACHE_FORMAT', '')</code> <code>key</code> <code>str</code> <p>Your API key.</p> <code>getenv('RECEPTIVITI_KEY', '')</code> <code>secret</code> <code>str</code> <p>Your API secret.</p> <code>getenv('RECEPTIVITI_SECRET', '')</code> <code>url</code> <code>str</code> <p>The URL of the API; defaults to <code>https://api.receptiviti.com</code>.</p> <code>getenv('RECEPTIVITI_URL', '')</code> <code>version</code> <code>str</code> <p>Version of the API; defaults to <code>v1</code>.</p> <code>getenv('RECEPTIVITI_VERSION', '')</code> <code>endpoint</code> <code>str</code> <p>Endpoint of the API; defaults to <code>framework</code>.</p> <code>getenv('RECEPTIVITI_ENDPOINT', '')</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>Scores associated with each input text.</p> <p>Examples:</p> <p>Score a single text</p> <pre><code>&gt;&gt;&gt; single = receptiviti.request(\"a text to score\")\n</code></pre> <p>Score multiple texts, and write results to a file</p> <pre><code>&gt;&gt;&gt; multi = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n</code></pre> <p>Score many texts in separate files</p> <pre><code>&gt;&gt;&gt; file_results = receptiviti.request(\n&gt;&gt;&gt;     directory=\"./path/to/csv_folder\", text_column=\"text\", file_type=\"csv\"\n&gt;&gt;&gt; )\n</code></pre> Cache <p>If <code>cache</code> is specified, results for unique texts are saved in an Arrow database in the cache location (<code>os.getenv(\"RECEPTIVITI_CACHE\")</code>), and are retrieved with subsequent requests. This ensures that the exact same texts are not re-sent to the API. This does, however, add some processing time and disc space usage.</p> <p>If <code>cache</code> if <code>True</code>, a default directory (<code>receptiviti_cache</code>) will be looked for in the system's temporary directory (<code>tempfile.gettempdir()</code>).</p> <p>The primary cache is checked when each bundle is processed, and existing results are loaded at that time. When processing many bundles in parallel, and many results have been cached, this can cause the system to freeze and potentially crash. To avoid this, limit the number of cores, or disable parallel processing.</p> <p>The <code>cache_format</code> arguments (or the <code>RECEPTIVITI_CACHE_FORMAT</code> environment variable) can be used to adjust the format of the cache.</p> <p>You can use the cache independently with <code>pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))</code>.</p> <p>You can also set the <code>clear_cache</code> argument to <code>True</code> to clear the cache before it is used again, which may be useful if the cache has gotten big, or you know new results will be returned.</p> <p>Even if a cached result exists, it will be reprocessed if it does not have all of the variables of new results, but this depends on there being at least 1 uncached result. If, for instance, you add a framework to your account and want to reprocess a previously processed set of texts, you would need to first clear the cache.</p> <p>Either way, duplicated texts within the same call will only be sent once.</p> <p>The <code>request_cache</code> argument controls a more temporary cache of each bundle request. This is cleared after a day. You might want to set this to <code>False</code> if a new framework becomes available on your account and you want to process a set of text you re-processed recently.</p> <p>Another temporary cache is made when <code>in_memory</code> is <code>False</code>, which is the default when processing in parallel (when there is more than 1 bundle and <code>cores</code> is over 1). This is a temporary directory that contains a file for each unique bundle, which is read in as needed by the parallel workers.</p> Parallelization <p><code>text</code>s are split into bundles based on the <code>bundle_size</code> argument. Each bundle represents a single request to the API, which is why they are limited to 1000 texts and a total size of 10 MB. When there is more than one bundle and <code>cores</code> is greater than 1, bundles are processed by multiple cores.</p> <p>If you have texts spread across multiple files, they can be most efficiently processed in parallel if each file contains a single text (potentially collapsed from multiple lines). If files contain multiple texts (i.e., <code>collapse_lines=False</code>), then texts need to be read in before bundling in order to ensure bundles are under the length limit.</p> <p>If you are calling this function from a script, parallelization will involve rerunning that script in each process, so anything you don't want rerun should be protected by a check that <code>__name__</code> equals <code>\"__main__\"</code> (placed within an <code>if __name__ == \"__main__\":</code> clause).</p> Source code in <code>src\\receptiviti\\request.py</code> <pre><code>def request(\n    text: Union[str, List[str], pandas.DataFrame, None] = None,\n    output: Union[str, None] = None,\n    ids: Union[str, List[str], List[int], None] = None,\n    text_column: Union[str, None] = None,\n    id_column: Union[str, None] = None,\n    files: Union[List[str], None] = None,\n    directory: Union[str, None] = None,\n    file_type: str = \"txt\",\n    encoding: Union[str, None] = None,\n    return_text=False,\n    api_args: Union[dict, None] = None,\n    frameworks: Union[str, List[str], None] = None,\n    framework_prefix: Union[bool, None] = None,\n    bundle_size=1000,\n    bundle_byte_limit=75e5,\n    collapse_lines=False,\n    retry_limit=50,\n    clear_cache=False,\n    request_cache=True,\n    cores=1,\n    in_memory: Union[bool, None] = None,\n    verbose=False,\n    progress_bar: Union[str, bool] = os.getenv(\"RECEPTIVITI_PB\", \"True\"),\n    overwrite=False,\n    make_request=True,\n    text_as_paths=False,\n    dotenv: Union[bool, str] = True,\n    cache: Union[str, bool] = os.getenv(\"RECEPTIVITI_CACHE\", \"\"),\n    cache_overwrite=False,\n    cache_format=os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"\"),\n    key=os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret=os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    url=os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    version=os.getenv(\"RECEPTIVITI_VERSION\", \"\"),\n    endpoint=os.getenv(\"RECEPTIVITI_ENDPOINT\", \"\"),\n) -&gt; pandas.DataFrame | None:\n    \"\"\"\n    Send texts to be scored by the API.\n\n    Args:\n        text (str | list[str] | pandas.DataFrame): Text to be processed, as a string or vector of\n            strings containing the text itself, or the path to a file from which to read in text.\n            If a DataFrame, `text_column` is used to extract such a vector. A string may also\n            represent a directory in which to search for files. To best ensure paths are not\n            treated as texts, either set `text_as_path` to `True`, or use `directory` to enter\n            a directory path, or `files` to enter a vector of file paths.\n        output (str): Path to a file to write results to.\n        ids (str | list[str | int]): Vector of IDs for each `text`, or a column name in `text`\n            containing IDs.\n        text_column (str): Column name in `text` containing text.\n        id_column (str): Column name in `text` containing IDs.\n        files (list[str]): Vector of file paths, as alternate entry to `text`.\n        directory (str): A directory path to search for files in, as alternate entry to `text`.\n        file_type (str): Extension of the file(s) to be read in from a directory (`txt` or `csv`).\n        encoding (str | None): Encoding of file(s) to be read in; one of the\n            [standard encodings](https://docs.python.org/3/library/codecs.html#standard-encodings).\n            If this is `None` (default), encoding will be predicted for each file, but this can\n            potentially fail, resulting in mis-encoded characters. For best (and fastest) results,\n            specify encoding.\n        return_text (bool): If `True`, will include a `text` column in the output with the\n            original text.\n        api_args (dict): Additional arguments to include in the request.\n        frameworks (str | list): One or more names of frameworks to return.\n        framework_prefix (bool): If `False`, will drop framework prefix from column names.\n            If one framework is selected, will default to `False`.\n        bundle_size (int): Maximum number of texts per bundle.\n        bundle_byte_limit (float): Maximum byte size of each bundle.\n        collapse_lines (bool): If `True`, will treat files as containing single texts, and\n            collapse multiple lines.\n        retry_limit (int): Number of times to retry a failed request.\n        clear_cache (bool): If `True`, will delete the `cache` before processing.\n        request_cache (bool): If `False`, will not temporarily save raw requests for reuse\n            within a day.\n        cores (int): Number of CPU cores to use when processing multiple bundles.\n        in_memory (bool | None): If `False`, will write bundles to disc, to be loaded when\n            processed. Defaults to `True` when processing in parallel.\n        verbose (bool): If `True`, will print status messages and preserve the progress bar.\n        progress_bar (str | bool): If `False`, will not display a progress bar.\n        overwrite (bool): If `True`, will overwrite an existing `output` file.\n        text_as_paths (bool): If `True`, will explicitly mark `text` as a list of file paths.\n            Otherwise, this will be detected.\n        dotenv (bool | str): Path to a .env file to read environment variables from. By default,\n            will for a file in the current directory or `~/Documents`.\n            Passed to `readin_env` as `path`.\n        cache (bool | str): Path to a cache directory, or `True` to use the default directory.\n        cache_overwrite (bool): If `True`, will not check the cache for previously cached texts,\n            but will store results in the cache (unlike `cache = False`).\n        cache_format (str): File format of the cache, of available Arrow formats.\n        key (str): Your API key.\n        secret (str): Your API secret.\n        url (str): The URL of the API; defaults to `https://api.receptiviti.com`.\n        version (str): Version of the API; defaults to `v1`.\n        endpoint (str): Endpoint of the API; defaults to `framework`.\n\n    Returns:\n        Scores associated with each input text.\n\n    Examples:\n        Score a single text\n        &gt;&gt;&gt; single = receptiviti.request(\"a text to score\")\n\n        Score multiple texts, and write results to a file\n        &gt;&gt;&gt; multi = receptiviti.request([\"first text to score\", \"second text\"], \"filename.csv\")\n\n        Score many texts in separate files\n        &gt;&gt;&gt; file_results = receptiviti.request(\n        &gt;&gt;&gt;     directory=\"./path/to/csv_folder\", text_column=\"text\", file_type=\"csv\"\n        &gt;&gt;&gt; )\n\n    Cache:\n        If `cache` is specified, results for unique texts are saved in an Arrow database\n        in the cache location (`os.getenv(\"RECEPTIVITI_CACHE\")`), and are retrieved with\n        subsequent requests. This ensures that the exact same texts are not re-sent to the API.\n        This does, however, add some processing time and disc space usage.\n\n        If `cache` if `True`, a default directory (`receptiviti_cache`) will be\n        looked for in the system's temporary directory (`tempfile.gettempdir()`).\n\n        The primary cache is checked when each bundle is processed, and existing results are\n        loaded at that time. When processing many bundles in parallel, and many results have\n        been cached, this can cause the system to freeze and potentially crash.\n        To avoid this, limit the number of cores, or disable parallel processing.\n\n        The `cache_format` arguments (or the `RECEPTIVITI_CACHE_FORMAT` environment variable) can be\n        used to adjust the format of the cache.\n\n        You can use the cache independently with\n        `pyarrow.dataset.dataset(os.getenv(\"RECEPTIVITI_CACHE\"))`.\n\n        You can also set the `clear_cache` argument to `True` to clear the cache before it is used\n        again, which may be useful if the cache has gotten big, or you know new results will be\n        returned.\n\n        Even if a cached result exists, it will be reprocessed if it does not have all of the\n        variables of new results, but this depends on there being at least 1 uncached result. If,\n        for instance, you add a framework to your account and want to reprocess a previously\n        processed set of texts, you would need to first clear the cache.\n\n        Either way, duplicated texts within the same call will only be sent once.\n\n        The `request_cache` argument controls a more temporary cache of each bundle request. This\n        is cleared after a day. You might want to set this to `False` if a new framework becomes\n        available on your account and you want to process a set of text you re-processed recently.\n\n        Another temporary cache is made when `in_memory` is `False`, which is the default when\n        processing in parallel (when there is more than 1 bundle and `cores` is over 1). This is a\n        temporary directory that contains a file for each unique bundle, which is read in as needed\n        by the parallel workers.\n\n    Parallelization:\n        `text`s are split into bundles based on the `bundle_size` argument. Each bundle represents\n        a single request to the API, which is why they are limited to 1000 texts and a total size\n        of 10 MB. When there is more than one bundle and `cores` is greater than 1, bundles are\n        processed by multiple cores.\n\n        If you have texts spread across multiple files, they can be most efficiently processed in\n        parallel if each file contains a single text (potentially collapsed from multiple lines).\n        If files contain multiple texts (i.e., `collapse_lines=False`), then texts need to be\n        read in before bundling in order to ensure bundles are under the length limit.\n\n        If you are calling this function from a script, parallelization will involve rerunning\n        that script in each process, so anything you don't want rerun should be protected by\n        a check that `__name__` equals `\"__main__\"`\n        (placed within an `if __name__ == \"__main__\":` clause).\n    \"\"\"\n    if cores &gt; 1 and current_process().name != \"MainProcess\":\n        return None\n    if output is not None and os.path.isfile(output) and not overwrite:\n        msg = \"`output` file already exists; use `overwrite=True` to overwrite it\"\n        raise RuntimeError(msg)\n    start_time = perf_counter()\n\n    # check norming context status\n    if api_args and \"custom_context\" in api_args:\n        if \"context\" in api_args:\n            msg = \"only one of `context` or `custom_context` may be specified\"\n            raise RuntimeError(msg)\n        if verbose:\n            print(f\"retrieving custom norming list ({perf_counter() - start_time:.4f})\")\n        norming_status: pandas.DataFrame = norming(url=url, key=key, secret=secret, verbose=False)\n        if len(norming_status) == 0 or api_args[\"custom_context\"] not in norming_status[\"name\"].values:\n            msg = f\"custom norming context {api_args['custom_context']} is not on record\"\n            raise RuntimeError(msg)\n        norming_status = norming_status[norming_status[\"name\"] == api_args[\"custom_context\"]]\n        if norming_status.iloc[0][\"status\"] != \"completed\":\n            msg = f\"custom norming context {api_args['custom_context']} has not been completed\"\n            raise RuntimeError(msg)\n\n    if isinstance(cache, str) and cache:\n        if clear_cache and os.path.exists(cache):\n            shutil.rmtree(cache, True)\n        os.makedirs(cache, exist_ok=True)\n        if not cache_format:\n            cache_format = os.getenv(\"RECEPTIVITI_CACHE_FORMAT\", \"parquet\")\n        if cache_format not in [\"parquet\", \"feather\"]:\n            msg = \"`cache_format` must be `parquet` or `feather`\"\n            raise RuntimeError(msg)\n    else:\n        cache = \"\"\n\n    data, res, id_specified = _manage_request(\n        text=text,\n        ids=ids,\n        text_column=text_column,\n        id_column=id_column,\n        files=files,\n        directory=directory,\n        file_type=file_type,\n        encoding=encoding,\n        api_args=api_args,\n        bundle_size=bundle_size,\n        bundle_byte_limit=bundle_byte_limit,\n        collapse_lines=collapse_lines,\n        retry_limit=retry_limit,\n        request_cache=request_cache,\n        cores=cores,\n        in_memory=in_memory,\n        verbose=verbose,\n        progress_bar=progress_bar,\n        make_request=make_request,\n        text_as_paths=text_as_paths,\n        dotenv=dotenv,\n        cache=cache,\n        cache_overwrite=cache_overwrite,\n        cache_format=cache_format,\n        key=key,\n        secret=secret,\n        url=url,\n        version=version,\n        endpoint=endpoint,\n    )\n\n    # finalize\n    if res is None or not res.shape[0]:\n        msg = \"no results\"\n        raise RuntimeError(msg)\n    if isinstance(cache, str):\n        writer = _get_writer(cache_format)\n        schema = pyarrow.schema(\n            (\n                col,\n                (\n                    pyarrow.string()\n                    if res[col].dtype == \"O\"\n                    else (\n                        pyarrow.int32()\n                        if col in [\"summary.word_count\", \"summary.sentence_count\"]\n                        else pyarrow.float32()\n                    )\n                ),\n            )\n            for col in res.columns\n            if col not in [\"id\", \"bin\", *(api_args.keys() if api_args else [])]\n        )\n        for bin_dir in glob(cache + \"/bin=*/\"):\n            _defragment_bin(bin_dir, cache_format, writer, schema)\n    if verbose:\n        print(f\"preparing output ({perf_counter() - start_time:.4f})\")\n    data.set_index(\"id\", inplace=True)\n    res.set_index(\"id\", inplace=True)\n    if len(res) != len(data):\n        res = res.join(data[\"text\"])\n        data_absent = data.loc[list(set(data.index).difference(res.index))]\n        data_absent = data_absent.loc[data_absent[\"text\"].isin(res[\"text\"])]\n        if data.size:\n            res = res.reset_index()\n            res.set_index(\"text\", inplace=True)\n            data_dupes = res.loc[data_absent[\"text\"]]\n            data_dupes[\"id\"] = data_absent.index.to_list()\n            res = pandas.concat([res, data_dupes])\n            res.reset_index(inplace=True, drop=True)\n            res.set_index(\"id\", inplace=True)\n    res = res.join(data[\"text\"], how=\"right\")\n    if not return_text:\n        res.drop(\"text\", axis=1, inplace=True)\n    res = res.reset_index()\n\n    if output is not None:\n        if verbose:\n            print(f\"writing results to file: {output} ({perf_counter() - start_time:.4f})\")\n        res.to_csv(output, index=False)\n\n    drops = [\"custom\", \"bin\"]\n    if not id_specified:\n        drops.append(\"id\")\n    res.drop(\n        list({*drops}.intersection(res.columns)),\n        axis=\"columns\",\n        inplace=True,\n    )\n    if frameworks is not None:\n        if verbose:\n            print(f\"selecting frameworks ({perf_counter() - start_time:.4f})\")\n        if isinstance(frameworks, str):\n            frameworks = [frameworks]\n        if len(frameworks) == 1 and framework_prefix is None:\n            framework_prefix = False\n        select = []\n        if id_specified:\n            select.append(\"id\")\n        if return_text:\n            select.append(\"text\")\n        select.append(\"text_hash\")\n        res = res.filter(regex=f\"^(?:{'|'.join(select + frameworks)})(?:$|\\\\.)\")\n    if isinstance(framework_prefix, bool) and not framework_prefix:\n        prefix_pattern = re.compile(\"^[^.]+\\\\.\")\n        res.columns = pandas.Index([prefix_pattern.sub(\"\", col) for col in res.columns])\n\n    if verbose:\n        print(f\"done ({perf_counter() - start_time:.4f})\")\n\n    return res\n</code></pre>"},{"location":"functions/status/","title":"Status","text":"<p>Check the status of the API.</p>"},{"location":"functions/status/#receptiviti.status.status","title":"<code>status(url=os.getenv('RECEPTIVITI_URL', ''), key=os.getenv('RECEPTIVITI_KEY', ''), secret=os.getenv('RECEPTIVITI_SECRET', ''), dotenv=False, verbose=True)</code>","text":"<p>Check the API's status.</p> <p>Ping the Receptiviti API to see if it's available, and if your credentials are valid.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the API.</p> <code>getenv('RECEPTIVITI_URL', '')</code> <code>key</code> <code>str</code> <p>Your API key.</p> <code>getenv('RECEPTIVITI_KEY', '')</code> <code>secret</code> <code>str</code> <p>Your API secret.</p> <code>getenv('RECEPTIVITI_SECRET', '')</code> <code>dotenv</code> <code>bool | str</code> <p>Path to a .env file to read environment variables from, or <code>True</code> to look for a file in the current directory.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If <code>False</code>, will not print status messages.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Response, None]</code> <p>Response from the API server.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; receptiviti.status()\n</code></pre> Source code in <code>src\\receptiviti\\status.py</code> <pre><code>def status(\n    url: str = os.getenv(\"RECEPTIVITI_URL\", \"\"),\n    key: str = os.getenv(\"RECEPTIVITI_KEY\", \"\"),\n    secret: str = os.getenv(\"RECEPTIVITI_SECRET\", \"\"),\n    dotenv: Union[bool, str] = False,\n    verbose=True,\n) -&gt; Union[requests.Response, None]:\n    \"\"\"\n    Check the API's status.\n\n    Ping the Receptiviti API to see if it's available, and if your credentials are valid.\n\n    Args:\n      url (str): The URL of the API.\n      key (str): Your API key.\n      secret (str): Your API secret.\n      dotenv (bool | str): Path to a .env file to read environment variables from, or `True`\n        to look for a file in the current directory.\n      verbose (bool): If `False`, will not print status messages.\n\n    Returns:\n      Response from the API server.\n\n    Examples:\n        &gt;&gt;&gt; receptiviti.status()\n    \"\"\"\n    if dotenv is not None and dotenv:\n        readin_env(\".\" if isinstance(dotenv, bool) else dotenv)\n    if not url:\n        url = os.getenv(\"RECEPTIVITI_URL\", \"https://api.receptiviti.com\")\n    if not key:\n        key = os.getenv(\"RECEPTIVITI_KEY\", \"\")\n    if not secret:\n        secret = os.getenv(\"RECEPTIVITI_SECRET\", \"\")\n    url = (\"https://\" if re.match(\"http\", url, re.I) is None else \"\") + re.sub(\"/[Vv]\\\\d(?:/.*)?$|/+$\", \"\", url)\n    if re.match(\"https?://[^.]+[.:][^.]\", url, re.I) is None:\n        raise TypeError(\"`url` does not appear to be valid: \" + url)\n    try:\n        res = requests.get(url.lower() + \"/v1/ping\", auth=(key, secret), timeout=9999)\n    except requests.exceptions.RequestException:\n        if verbose:\n            print(\"Status: ERROR\\nMessage: URL is unreachable\")\n        return None\n    content = res.json() if res.text[:1] == \"{\" else {\"message\": res.text}\n    if verbose:\n        print(\"Status: \" + (\"OK\" if res.status_code == 200 else \"ERROR\"))\n        print(\n            \"Message: \"\n            + (\n                str(res.status_code)\n                + (\" (\" + str(content[\"code\"]) + \")\" if \"code\" in content else \"\")\n                + \": \"\n                + content[\"pong\" if \"pong\" in content else \"message\"]\n            )\n        )\n    return res\n</code></pre>"}]}